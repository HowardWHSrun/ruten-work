{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3 - Normal Vector Stability Analysis\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook analyzes the stability of normal vectors computed from a reference plane defined by 3 landmark nodes. It quantifies stability metrics, measures directional changes over time, and provides longer-period state estimates. Additionally, it performs across-frame distribution analysis, worst-case identification, and nose point stability analysis.\n",
    "\n",
    "## What This Analysis Does\n",
    "\n",
    "The analysis computes plane normal vectors from 3 landmark points (typically head landmarks) and measures:\n",
    "1. **Normal Vector Stability**: How stable the plane orientation is over time\n",
    "2. **Angle Changes**: Frame-to-frame angular changes in the normal vector direction\n",
    "3. **Angular Velocity**: Rate of change of normal vector direction\n",
    "4. **Rolling Statistics**: Mean normal vectors over different time windows (0.5s, 1s, 5s)\n",
    "5. **State Classification**: Classifies each frame as \"stable\" or \"changing\" based on stability metrics\n",
    "6. **Per-Second Analysis**: Mean normal vector per second and angle shifts between seconds\n",
    "7. **Across-Frame Distribution**: Statistical distributions of all metrics with skewness and kurtosis\n",
    "8. **Worst-Case Analysis**: Identifies outlier frames, maximum deviations, and unstable periods\n",
    "9. **Nose Point Stability**: Dedicated analysis of nose point (node_3) positional stability\n",
    "\n",
    "## Methodology\n",
    "\n",
    "### 1. Plane Normal Computation\n",
    "- For each frame, compute the plane normal vector from 3 landmark points using cross product\n",
    "- Normalize the vector to unit length\n",
    "- The normal vector represents the orientation of the reference plane\n",
    "\n",
    "### 2. Angle Change Metrics\n",
    "- **Frame-to-frame angle change**: Angle between consecutive normal vectors\n",
    "- **Cumulative angle change**: Total angle change from the first valid frame\n",
    "- **Angular velocity**: Rate of change in degrees per second\n",
    "\n",
    "### 3. Rolling Statistics\n",
    "- Compute rolling mean normal vectors over windows of 0.5s, 1s, and 5s\n",
    "- Compute rolling standard deviation of angles from the rolling mean\n",
    "- These provide smoothed estimates of normal vector direction\n",
    "\n",
    "### 4. Low-Pass Filtering\n",
    "- Apply Butterworth low-pass filter (5 Hz cutoff) to reduce high-frequency noise\n",
    "- Helps separate real directional changes from tracking noise\n",
    "\n",
    "### 5. State Classification\n",
    "- Classify frames as \"stable\" or \"changing\" based on rolling standard deviation\n",
    "- Threshold: < 5 degrees = stable, >= 5 degrees = changing\n",
    "\n",
    "### 6. Per-Second Block Analysis\n",
    "- Compute mean normal vector for each 1-second block\n",
    "- Compute angle shift between consecutive seconds\n",
    "- Enforces continuity to avoid 180-degree jumps\n",
    "\n",
    "### 7. Across-Frame Distribution Analysis\n",
    "- Compute full statistical distributions for angle changes, angular velocity, and normal vector components\n",
    "- Calculate percentiles (25th, 75th, 95th, 99th), skewness, and kurtosis\n",
    "- Helps characterize the shape and spread of metric distributions\n",
    "\n",
    "### 8. Worst-Case Analysis\n",
    "- **Maximum deviation**: Largest angle deviation from mean normal vector\n",
    "- **Outlier detection**: Frames with angle changes exceeding 3 standard deviations\n",
    "- **Unstable periods**: Contiguous time periods where stability std exceeds threshold\n",
    "- **Maximum angular velocity**: Frames with highest rate of directional change\n",
    "\n",
    "### 9. Nose Point (node_3) Stability Analysis\n",
    "- Track 3D position of nose point across all frames\n",
    "- Compute displacement from mean position (overall and per-axis)\n",
    "- Measure frame-to-frame displacement and velocity\n",
    "- Calculate rolling position stability using 1-second windows\n",
    "- Identify periods of high nose movement\n",
    "\n",
    "## Outputs\n",
    "\n",
    "- `normal_vector_stability_analysis.csv`: Frame-by-frame results with all metrics\n",
    "- `normal_vector_stability_sec_blocks.csv`: Per-second block analysis with angle shifts\n",
    "- `distribution_statistics.csv`: Summary statistics for all metric distributions\n",
    "- `worst_case_frames.csv`: Identified outlier frames and worst-case events\n",
    "- `nose_point_stability.csv`: Frame-by-frame nose point position and stability metrics\n",
    "- Summary statistics printed to console\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PHASE 3 \u2022 NORMAL VECTOR STABILITY ANALYSIS ============================\n",
    "# Analyzes the stability of normal vectors computed from a reference plane\n",
    "# defined by 3 landmark nodes.\n",
    "#\n",
    "# INPUT:\n",
    "#   csv_path: Path to CSV file with 3D node data (columns: frame, node, x, y, z, time_s)\n",
    "#   fps: Frames per second (default 120.0)\n",
    "#   landmark_nodes: List of 3 node names to use for plane computation\n",
    "#\n",
    "# OUTPUT:\n",
    "#   normal_vector_stability_analysis.csv: Frame-by-frame results\n",
    "#   normal_vector_stability_sec_blocks.csv: Per-second block analysis\n",
    "# ============================================================================\n",
    "\n",
    "# ===================== USER CONFIGURATION =====================\n",
    "csv_path = r\"/Users/howardwang/Desktop/Ruten/Evaluation-Metrics_Vishal-main/face/results/n20/triangulated/session_2025-05-28_14-12-04_124591_v1/all_nodes_3d_long_v1.csv\"  # Path to 3D node data CSV\n",
    "fps = 120.0  # Frames per second\n",
    "landmark_nodes = ['node_1', 'node_2', 'node_3']  # 3 nodes to define reference plane\n",
    "\n",
    "# Output directory\n",
    "out_root = r\"/Users/howardwang/Desktop/Ruten/Evaluation-Metrics_Vishal-main/face/results/n20/phase3_step1\"  # Output directory for results\n",
    "\n",
    "# Analysis parameters\n",
    "stability_threshold_deg = 5.0  # Threshold for stable/changing classification (degrees)\n",
    "lowpass_cutoff_hz = 5.0  # Low-pass filter cutoff frequency (Hz)\n",
    "# ==============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scipy import signal\n",
    "import os\n",
    "\n",
    "os.makedirs(out_root, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== HELPER FUNCTIONS =====================\n",
    "\n",
    "def load_and_structure_data(csv_path):\n",
    "    \"\"\"Load CSV data and convert to structured array format\"\"\"\n",
    "    print(\"Loading data...\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Get frames and nodes\n",
    "    frames = df['frame'].unique()\n",
    "    nodes = df['node'].unique()\n",
    "    print(f\"Frames: {len(frames)}, Nodes: {len(nodes)}\")\n",
    "    print(f\"Nodes: {nodes}\")\n",
    "    \n",
    "    # Prepare data array: frames x nodes x coordinates\n",
    "    n_frames = len(frames)\n",
    "    n_nodes = len(nodes)\n",
    "    X3 = np.full((n_frames, n_nodes, 3), np.nan)\n",
    "    \n",
    "    # Fill the array\n",
    "    for i, node in enumerate(nodes):\n",
    "        node_data = df[df['node'] == node]\n",
    "        for _, row in node_data.iterrows():\n",
    "            frame_idx = int(row['frame'])\n",
    "            if frame_idx < n_frames:\n",
    "                X3[frame_idx, i, 0] = row['x'] if pd.notna(row['x']) else np.nan\n",
    "                X3[frame_idx, i, 1] = row['y'] if pd.notna(row['y']) else np.nan\n",
    "                X3[frame_idx, i, 2] = row['z'] if pd.notna(row['z']) else np.nan\n",
    "    \n",
    "    # Get time array\n",
    "    times = df[df['node'] == nodes[0]]['time_s'].values\n",
    "    \n",
    "    return X3, frames, nodes, times\n",
    "\n",
    "\n",
    "def find_node_indices(nodes, target_nodes):\n",
    "    \"\"\"Find indices of target nodes in the nodes array\"\"\"\n",
    "    indices = []\n",
    "    for target in target_nodes:\n",
    "        for i, n in enumerate(nodes):\n",
    "            if n == target:\n",
    "                indices.append(i)\n",
    "                break\n",
    "    return indices\n",
    "\n",
    "\n",
    "def compute_plane_normal(X3, frame, landmark_indices):\n",
    "    \"\"\"\n",
    "    Compute plane normal vector from 3 landmark points\n",
    "    \n",
    "    Args:\n",
    "        X3: Data array (frames x nodes x coordinates)\n",
    "        frame: Current frame index\n",
    "        landmark_indices: Indices of 3 landmark nodes\n",
    "    \n",
    "    Returns:\n",
    "        normal: Normalized plane normal vector (3D) or None if invalid\n",
    "    \"\"\"\n",
    "    # Extract landmark positions\n",
    "    p1 = X3[frame, landmark_indices[0], :]\n",
    "    p2 = X3[frame, landmark_indices[1], :]\n",
    "    p3 = X3[frame, landmark_indices[2], :]\n",
    "    \n",
    "    # Check if all points are valid\n",
    "    if not (np.all(np.isfinite(p1)) and np.all(np.isfinite(p2)) and np.all(np.isfinite(p3))):\n",
    "        return None\n",
    "    \n",
    "    # Calculate plane normal via cross product\n",
    "    v1 = p2 - p1\n",
    "    v2 = p3 - p1\n",
    "    normal = np.cross(v1, v2)\n",
    "    norm_mag = np.linalg.norm(normal)\n",
    "    \n",
    "    if norm_mag < 1e-10:\n",
    "        return None\n",
    "    \n",
    "    normal = normal / norm_mag  # Normalize\n",
    "    \n",
    "    return normal\n",
    "\n",
    "\n",
    "def compute_normal_angle(n1, n2):\n",
    "    \"\"\"\n",
    "    Compute angle between two normal vectors in degrees\n",
    "    \n",
    "    Args:\n",
    "        n1, n2: Normalized normal vectors (3D arrays)\n",
    "    \n",
    "    Returns:\n",
    "        angle: Angle in degrees (0-180)\n",
    "    \"\"\"\n",
    "    if n1 is None or n2 is None:\n",
    "        return np.nan\n",
    "    \n",
    "    if not (np.all(np.isfinite(n1)) and np.all(np.isfinite(n2))):\n",
    "        return np.nan\n",
    "    \n",
    "    # Dot product (clamped to handle numerical errors)\n",
    "    dot_product = np.clip(np.dot(n1, n2), -1.0, 1.0)\n",
    "    angle_rad = np.arccos(dot_product)\n",
    "    angle_deg = np.degrees(angle_rad)\n",
    "    \n",
    "    return angle_deg\n",
    "\n",
    "\n",
    "def rolling_statistics(data, window_size_frames, func=np.mean, fill_value=np.nan):\n",
    "    \"\"\"\n",
    "    Compute rolling statistics over a window\n",
    "    \n",
    "    Args:\n",
    "        data: 1D or 2D array\n",
    "        window_size_frames: Window size in frames\n",
    "        func: Function to apply (np.mean, np.std, etc.)\n",
    "        fill_value: Value to use for insufficient data\n",
    "    \n",
    "    Returns:\n",
    "        Rolling statistics array\n",
    "    \"\"\"\n",
    "    if len(data) == 0:\n",
    "        return np.array([])\n",
    "    \n",
    "    # Handle 2D arrays (for vector data)\n",
    "    if data.ndim == 2:\n",
    "        n_frames, n_dims = data.shape\n",
    "        result = np.full((n_frames, n_dims), fill_value)\n",
    "        for i in range(n_frames):\n",
    "            start = max(0, i - window_size_frames // 2)\n",
    "            end = min(n_frames, i + window_size_frames // 2 + 1)\n",
    "            window_data = data[start:end, :]\n",
    "            valid_mask = np.all(np.isfinite(window_data), axis=1)\n",
    "            if np.sum(valid_mask) > 0:\n",
    "                result[i, :] = func(window_data[valid_mask], axis=0)\n",
    "    else:\n",
    "        # Handle 1D arrays\n",
    "        n_frames = len(data)\n",
    "        result = np.full(n_frames, fill_value)\n",
    "        for i in range(n_frames):\n",
    "            start = max(0, i - window_size_frames // 2)\n",
    "            end = min(n_frames, i + window_size_frames // 2 + 1)\n",
    "            window_data = data[start:end]\n",
    "            valid_mask = np.isfinite(window_data)\n",
    "            if np.sum(valid_mask) > 0:\n",
    "                result[i] = func(window_data[valid_mask])\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def apply_lowpass_filter(data, fps, cutoff_hz=5.0, order=4):\n",
    "    \"\"\"\n",
    "    Apply Butterworth low-pass filter to reduce high-frequency noise\n",
    "    \n",
    "    Args:\n",
    "        data: 2D array (n_frames x n_dims)\n",
    "        fps: Frames per second\n",
    "        cutoff_hz: Cutoff frequency in Hz\n",
    "        order: Filter order\n",
    "    \n",
    "    Returns:\n",
    "        Filtered data\n",
    "    \"\"\"\n",
    "    if len(data) == 0:\n",
    "        return data\n",
    "    \n",
    "    nyquist = fps / 2.0\n",
    "    if cutoff_hz >= nyquist:\n",
    "        cutoff_hz = nyquist * 0.95  # Ensure below Nyquist\n",
    "    \n",
    "    b, a = signal.butter(order, cutoff_hz / nyquist, btype='low')\n",
    "    \n",
    "    # Filter each dimension separately\n",
    "    filtered = np.full_like(data, np.nan)\n",
    "    for dim in range(data.shape[1]):\n",
    "        valid_mask = np.isfinite(data[:, dim])\n",
    "        if np.sum(valid_mask) > order * 2:  # Need enough points for filter\n",
    "            filtered_data = signal.filtfilt(b, a, data[valid_mask, dim])\n",
    "            filtered[valid_mask, dim] = filtered_data\n",
    "    \n",
    "    return filtered\n",
    "\n",
    "\n",
    "def compute_stability_metrics(normals):\n",
    "    \"\"\"\n",
    "    Compute overall stability metrics for normal vectors\n",
    "    \n",
    "    Args:\n",
    "        normals: Array of normal vectors (n_frames x 3)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with stability metrics\n",
    "    \"\"\"\n",
    "    # Filter out invalid normals\n",
    "    valid_mask = np.all(np.isfinite(normals), axis=1)\n",
    "    valid_normals = normals[valid_mask]\n",
    "    \n",
    "    if len(valid_normals) == 0:\n",
    "        return {\n",
    "            'mean_normal': np.array([np.nan, np.nan, np.nan]),\n",
    "            'std_components': np.array([np.nan, np.nan, np.nan]),\n",
    "            'mean_angular_dispersion': np.nan,\n",
    "            'coefficient_of_variation': np.nan\n",
    "        }\n",
    "    \n",
    "    # Mean normal vector\n",
    "    mean_normal = np.mean(valid_normals, axis=0)\n",
    "    mean_normal = mean_normal / np.linalg.norm(mean_normal)  # Normalize\n",
    "    \n",
    "    # Standard deviation of components\n",
    "    std_components = np.std(valid_normals, axis=0)\n",
    "    \n",
    "    # Angular dispersion: std dev of angles from mean normal\n",
    "    angles_from_mean = []\n",
    "    for n in valid_normals:\n",
    "        angle = compute_normal_angle(n, mean_normal)\n",
    "        if not np.isnan(angle):\n",
    "            angles_from_mean.append(angle)\n",
    "    \n",
    "    mean_angular_dispersion = np.std(angles_from_mean) if len(angles_from_mean) > 0 else np.nan\n",
    "    \n",
    "    # Coefficient of variation for normal magnitude (should be ~0 for unit vectors)\n",
    "    magnitudes = np.linalg.norm(valid_normals, axis=1)\n",
    "    mean_magnitude = np.mean(magnitudes)\n",
    "    std_magnitude = np.std(magnitudes)\n",
    "    coefficient_of_variation = (std_magnitude / mean_magnitude) if mean_magnitude > 0 else np.nan\n",
    "    \n",
    "    return {\n",
    "        'mean_normal': mean_normal,\n",
    "        'std_components': std_components,\n",
    "        'mean_angular_dispersion': mean_angular_dispersion,\n",
    "        'coefficient_of_variation': coefficient_of_variation\n",
    "    }\n",
    "\n",
    "\n",
    "def classify_state(normals_stability_std, threshold=5.0):\n",
    "    \"\"\"\n",
    "    Classify each frame as stable or changing based on rolling standard deviation\n",
    "    \n",
    "    Args:\n",
    "        normals_stability_std: Rolling standard deviation values\n",
    "        threshold: Threshold in degrees for classification\n",
    "    \n",
    "    Returns:\n",
    "        Array of state labels ('stable' or 'changing')\n",
    "    \"\"\"\n",
    "    states = np.full(len(normals_stability_std), 'changing', dtype=object)\n",
    "    valid_mask = np.isfinite(normals_stability_std)\n",
    "    states[valid_mask & (normals_stability_std < threshold)] = 'stable'\n",
    "    \n",
    "    return states\n",
    "# ==============================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== MAIN ANALYSIS =====================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Normal Vector Stability Analysis\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "dt = 1.0 / fps\n",
    "\n",
    "# Window sizes in frames\n",
    "window_0_5s = int(0.5 * fps)  # 60 frames\n",
    "window_1s = int(1.0 * fps)    # 120 frames\n",
    "window_5s = int(5.0 * fps)    # 600 frames\n",
    "window_10s = int(10.0 * fps)  # 1200 frames\n",
    "\n",
    "# Load data\n",
    "X3, frames, nodes, times = load_and_structure_data(csv_path)\n",
    "\n",
    "# Find landmark indices\n",
    "landmark_indices = find_node_indices(nodes, landmark_nodes)\n",
    "if len(landmark_indices) != 3:\n",
    "    print(f\"Error: Could not find all landmarks. Expected {landmark_nodes}\")\n",
    "    print(f\"Found indices: {landmark_indices}\")\n",
    "    raise RuntimeError(f\"Could not find all landmarks: {landmark_nodes}\")\n",
    "\n",
    "print(f\"\\nLandmark nodes: {landmark_nodes}\")\n",
    "print(f\"Landmark indices: {landmark_indices}\")\n",
    "\n",
    "n_frames = len(frames)\n",
    "\n",
    "# Compute normal vectors for all frames\n",
    "print(\"\\nComputing normal vectors...\")\n",
    "normals = np.full((n_frames, 3), np.nan)\n",
    "\n",
    "for i in range(n_frames):\n",
    "    normal = compute_plane_normal(X3, i, landmark_indices)\n",
    "    if normal is not None:\n",
    "        normals[i, :] = normal\n",
    "\n",
    "valid_normal_count = np.sum(np.all(np.isfinite(normals), axis=1))\n",
    "print(f\"Computed {valid_normal_count} valid normal vectors out of {n_frames} frames\")\n",
    "\n",
    "# Compute angle changes\n",
    "print(\"\\nComputing angle changes...\")\n",
    "angle_changes = np.full(n_frames, np.nan)\n",
    "cumulative_angle_changes = np.full(n_frames, np.nan)\n",
    "angular_velocities = np.full(n_frames, np.nan)\n",
    "\n",
    "for i in range(1, n_frames):\n",
    "    if np.all(np.isfinite(normals[i, :])) and np.all(np.isfinite(normals[i-1, :])):\n",
    "        angle = compute_normal_angle(normals[i-1, :], normals[i, :])\n",
    "        angle_changes[i] = angle\n",
    "        \n",
    "        # Angular velocity (degrees per second)\n",
    "        if not np.isnan(angle):\n",
    "            angular_velocities[i] = angle / dt\n",
    "\n",
    "# Cumulative angle change from first frame\n",
    "cumulative_angle = 0.0\n",
    "first_valid_idx = None\n",
    "for i in range(n_frames):\n",
    "    if np.all(np.isfinite(normals[i, :])):\n",
    "        if first_valid_idx is None:\n",
    "            first_valid_idx = i\n",
    "            cumulative_angle_changes[i] = 0.0\n",
    "        elif first_valid_idx is not None:\n",
    "            angle = compute_normal_angle(normals[first_valid_idx, :], normals[i, :])\n",
    "            if not np.isnan(angle):\n",
    "                cumulative_angle = angle\n",
    "                cumulative_angle_changes[i] = cumulative_angle\n",
    "\n",
    "# Rolling statistics\n",
    "print(\"\\nComputing rolling statistics...\")\n",
    "\n",
    "# Rolling mean normal vectors (0.5s, 1s, 5s windows)\n",
    "rolling_mean_0_5s = rolling_statistics(normals, window_0_5s, func=np.mean)\n",
    "rolling_mean_1s = rolling_statistics(normals, window_1s, func=np.mean)\n",
    "rolling_mean_5s = rolling_statistics(normals, window_5s, func=np.mean)\n",
    "\n",
    "# Normalize rolling means\n",
    "for i in range(n_frames):\n",
    "    if np.all(np.isfinite(rolling_mean_0_5s[i, :])):\n",
    "        rolling_mean_0_5s[i, :] = rolling_mean_0_5s[i, :] / np.linalg.norm(rolling_mean_0_5s[i, :])\n",
    "    if np.all(np.isfinite(rolling_mean_1s[i, :])):\n",
    "        rolling_mean_1s[i, :] = rolling_mean_1s[i, :] / np.linalg.norm(rolling_mean_1s[i, :])\n",
    "    if np.all(np.isfinite(rolling_mean_5s[i, :])):\n",
    "        rolling_mean_5s[i, :] = rolling_mean_5s[i, :] / np.linalg.norm(rolling_mean_5s[i, :])\n",
    "\n",
    "# Rolling standard deviation of angles (using 1s window)\n",
    "reference_normal = rolling_mean_1s\n",
    "normals_stability_std = np.full(n_frames, np.nan)\n",
    "normals_stability_mean_angle = np.full(n_frames, np.nan)\n",
    "\n",
    "for i in range(n_frames):\n",
    "    if np.all(np.isfinite(normals[i, :])) and np.all(np.isfinite(reference_normal[i, :])):\n",
    "        # Angle from current normal to rolling mean\n",
    "        angle = compute_normal_angle(normals[i, :], reference_normal[i, :])\n",
    "        normals_stability_mean_angle[i] = angle\n",
    "        \n",
    "        # Rolling std of angles in window\n",
    "        start = max(0, i - window_1s // 2)\n",
    "        end = min(n_frames, i + window_1s // 2 + 1)\n",
    "        window_angles = normals_stability_mean_angle[start:end]\n",
    "        valid_angles = window_angles[np.isfinite(window_angles)]\n",
    "        if len(valid_angles) > 1:\n",
    "            normals_stability_std[i] = np.std(valid_angles)\n",
    "\n",
    "# Low-pass filtered normals\n",
    "print(\"Applying low-pass filter...\")\n",
    "filtered_normals = apply_lowpass_filter(normals, fps, cutoff_hz=lowpass_cutoff_hz)\n",
    "# Normalize filtered normals\n",
    "for i in range(n_frames):\n",
    "    if np.all(np.isfinite(filtered_normals[i, :])):\n",
    "        filtered_normals[i, :] = filtered_normals[i, :] / np.linalg.norm(filtered_normals[i, :])\n",
    "\n",
    "# State classification\n",
    "print(\"Classifying states...\")\n",
    "state_labels = classify_state(normals_stability_std, threshold=stability_threshold_deg)\n",
    "\n",
    "# Overall stability metrics\n",
    "print(\"\\nComputing overall stability metrics...\")\n",
    "stability_metrics = compute_stability_metrics(normals)\n",
    "\n",
    "# Create output DataFrame\n",
    "print(\"\\nCreating output DataFrame...\")\n",
    "results = []\n",
    "\n",
    "for i in range(n_frames):\n",
    "    result_row = {\n",
    "        'frame': frames[i],\n",
    "        'time_s': times[i],\n",
    "        'normal_x': normals[i, 0] if np.isfinite(normals[i, 0]) else np.nan,\n",
    "        'normal_y': normals[i, 1] if np.isfinite(normals[i, 1]) else np.nan,\n",
    "        'normal_z': normals[i, 2] if np.isfinite(normals[i, 2]) else np.nan,\n",
    "        'angle_change_deg': angle_changes[i] if np.isfinite(angle_changes[i]) else np.nan,\n",
    "        'cumulative_angle_change_deg': cumulative_angle_changes[i] if np.isfinite(cumulative_angle_changes[i]) else np.nan,\n",
    "        'angular_velocity_deg_per_s': angular_velocities[i] if np.isfinite(angular_velocities[i]) else np.nan,\n",
    "        'normal_stability_std': normals_stability_std[i] if np.isfinite(normals_stability_std[i]) else np.nan,\n",
    "        'normal_stability_mean_angle': normals_stability_mean_angle[i] if np.isfinite(normals_stability_mean_angle[i]) else np.nan,\n",
    "        'state_label': state_labels[i],\n",
    "        'filtered_normal_x': filtered_normals[i, 0] if np.isfinite(filtered_normals[i, 0]) else np.nan,\n",
    "        'filtered_normal_y': filtered_normals[i, 1] if np.isfinite(filtered_normals[i, 1]) else np.nan,\n",
    "        'filtered_normal_z': filtered_normals[i, 2] if np.isfinite(filtered_normals[i, 2]) else np.nan,\n",
    "    }\n",
    "    results.append(result_row)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Per-second block analysis: mean normal per second and angle shift\n",
    "print(\"\\nComputing per-second block angle shifts...\")\n",
    "normals_df = pd.DataFrame({\n",
    "    'time_s': times,\n",
    "    'normal_x': normals[:, 0],\n",
    "    'normal_y': normals[:, 1],\n",
    "    'normal_z': normals[:, 2],\n",
    "})\n",
    "normals_df['second'] = np.floor(normals_df['time_s']).astype(int)\n",
    "\n",
    "sec_rows = []\n",
    "for sec, grp in normals_df.groupby('second'):\n",
    "    vals = grp[['normal_x', 'normal_y', 'normal_z']].values\n",
    "    valid = np.all(np.isfinite(vals), axis=1)\n",
    "    if valid.sum() == 0:\n",
    "        continue\n",
    "    mean_vec = np.mean(vals[valid], axis=0)\n",
    "    if np.all(np.isfinite(mean_vec)) and np.linalg.norm(mean_vec) > 0:\n",
    "        mean_vec = mean_vec / np.linalg.norm(mean_vec)\n",
    "        sec_rows.append({\n",
    "            'second': int(sec),\n",
    "            'time_start_s': float(sec),\n",
    "            'time_end_s': float(sec + 1),\n",
    "            'mean_normal_x': mean_vec[0],\n",
    "            'mean_normal_y': mean_vec[1],\n",
    "            'mean_normal_z': mean_vec[2],\n",
    "            'num_valid_frames': int(valid.sum()),\n",
    "            'num_frames_in_sec': int(len(valid))\n",
    "        })\n",
    "\n",
    "sec_df = pd.DataFrame(sec_rows).sort_values('second').reset_index(drop=True)\n",
    "\n",
    "# Enforce continuity (flip sign if necessary) to avoid 180-deg jumps\n",
    "def angle_deg(n1, n2):\n",
    "    dp = np.clip(np.dot(n1, n2), -1.0, 1.0)\n",
    "    return float(np.degrees(np.arccos(dp)))\n",
    "\n",
    "prev = None\n",
    "for i in range(len(sec_df)):\n",
    "    curr = sec_df.loc[i, ['mean_normal_x','mean_normal_y','mean_normal_z']].values.astype(float)\n",
    "    if prev is not None and np.all(np.isfinite(prev)) and np.all(np.isfinite(curr)):\n",
    "        if np.dot(prev, curr) < 0:\n",
    "            curr = -curr\n",
    "            sec_df.loc[i, ['mean_normal_x','mean_normal_y','mean_normal_z']] = curr\n",
    "    prev = curr\n",
    "\n",
    "# Compute sec-to-sec angle shifts\n",
    "angles = [np.nan]\n",
    "for i in range(1, len(sec_df)):\n",
    "    n1 = sec_df.loc[i-1, ['mean_normal_x','mean_normal_y','mean_normal_z']].values.astype(float)\n",
    "    n2 = sec_df.loc[i,   ['mean_normal_x','mean_normal_y','mean_normal_z']].values.astype(float)\n",
    "    angles.append(angle_deg(n1, n2))\n",
    "sec_df['angle_to_prev_sec_deg'] = angles\n",
    "\n",
    "# Save per-second analysis\n",
    "sec_out = Path(out_root) / 'normal_vector_stability_sec_blocks.csv'\n",
    "sec_out.parent.mkdir(exist_ok=True, parents=True)\n",
    "sec_df.to_csv(sec_out, index=False)\n",
    "print(f\"Per-second block analysis saved to: {sec_out}\")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "valid_mask = np.all(np.isfinite(normals), axis=1)\n",
    "valid_count = np.sum(valid_mask)\n",
    "\n",
    "print(f\"\\nOverall Stability Metrics:\")\n",
    "print(f\"  Mean normal vector: [{stability_metrics['mean_normal'][0]:.6f}, \"\n",
    "      f\"{stability_metrics['mean_normal'][1]:.6f}, {stability_metrics['mean_normal'][2]:.6f}]\")\n",
    "print(f\"  Std dev of components: [{stability_metrics['std_components'][0]:.6f}, \"\n",
    "      f\"{stability_metrics['std_components'][1]:.6f}, {stability_metrics['std_components'][2]:.6f}]\")\n",
    "print(f\"  Mean angular dispersion: {stability_metrics['mean_angular_dispersion']:.4f} degrees\")\n",
    "print(f\"  Coefficient of variation: {stability_metrics['coefficient_of_variation']:.6f}\")\n",
    "\n",
    "print(f\"\\nAngle Change Statistics:\")\n",
    "valid_angles = angle_changes[np.isfinite(angle_changes)]\n",
    "if len(valid_angles) > 0:\n",
    "    print(f\"  Mean angle change: {np.mean(valid_angles):.4f} degrees\")\n",
    "    print(f\"  Std dev angle change: {np.std(valid_angles):.4f} degrees\")\n",
    "    print(f\"  Max angle change: {np.max(valid_angles):.4f} degrees\")\n",
    "    print(f\"  Min angle change: {np.min(valid_angles):.4f} degrees\")\n",
    "\n",
    "print(f\"\\nAngular Velocity Statistics:\")\n",
    "valid_velocities = angular_velocities[np.isfinite(angular_velocities)]\n",
    "if len(valid_velocities) > 0:\n",
    "    print(f\"  Mean angular velocity: {np.mean(valid_velocities):.4f} deg/s\")\n",
    "    print(f\"  Max angular velocity: {np.max(valid_velocities):.4f} deg/s\")\n",
    "\n",
    "# Per-second summary\n",
    "if len(sec_df) > 1:\n",
    "    valid_sec_angles = sec_df['angle_to_prev_sec_deg'].dropna()\n",
    "    if len(valid_sec_angles) > 0:\n",
    "        print(f\"\\nPer-second angle shift (sec-to-sec):\")\n",
    "        print(f\"  Mean: {valid_sec_angles.mean():.4f} deg/sec\")\n",
    "        print(f\"  Median: {valid_sec_angles.median():.4f} deg/sec\")\n",
    "        print(f\"  Max: {valid_sec_angles.max():.4f} deg/sec\")\n",
    "\n",
    "print(f\"\\nState Classification:\")\n",
    "stable_count = np.sum(state_labels == 'stable')\n",
    "changing_count = np.sum(state_labels == 'changing')\n",
    "stable_percent = 100 * stable_count / n_frames if n_frames > 0 else 0\n",
    "changing_percent = 100 * changing_count / n_frames if n_frames > 0 else 0\n",
    "print(f\"  Stable frames: {stable_percent:.2f}% ({stable_count} frames)\")\n",
    "print(f\"  Changing frames: {changing_percent:.2f}% ({changing_count} frames)\")\n",
    "\n",
    "# Time periods with highest/lowest stability\n",
    "valid_stability = normals_stability_std[np.isfinite(normals_stability_std)]\n",
    "if len(valid_stability) > 0:\n",
    "    min_stability_idx = np.argmin(valid_stability)\n",
    "    max_stability_idx = np.argmax(valid_stability)\n",
    "    min_stability_time = times[np.where(np.isfinite(normals_stability_std))[0][min_stability_idx]]\n",
    "    max_stability_time = times[np.where(np.isfinite(normals_stability_std))[0][max_stability_idx]]\n",
    "    \n",
    "    print(f\"\\nStability Periods:\")\n",
    "    print(f\"  Most stable time: {min_stability_time:.3f} s (std: {np.min(valid_stability):.4f} deg)\")\n",
    "    print(f\"  Least stable time: {max_stability_time:.3f} s (std: {np.max(valid_stability):.4f} deg)\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Save results\n",
    "output_path = Path(out_root) / 'normal_vector_stability_analysis.csv'\n",
    "output_path.parent.mkdir(exist_ok=True, parents=True)\n",
    "results_df.to_csv(output_path, index=False)\n",
    "print(f\"\\nResults saved to: {output_path}\")\n",
    "print(\"[DONE]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== ACROSS-FRAME DISTRIBUTION ANALYSIS =====================\n",
    "# Computes and displays distribution statistics for angle changes, normal vector\n",
    "# components, and angular velocity across all frames.\n",
    "# ==============================================================================\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ACROSS-FRAME DISTRIBUTION ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Prepare valid data arrays\n",
    "valid_angle_changes = angle_changes[np.isfinite(angle_changes)]\n",
    "valid_angular_velocities = angular_velocities[np.isfinite(angular_velocities)]\n",
    "valid_normal_x = normals[:, 0][np.isfinite(normals[:, 0])]\n",
    "valid_normal_y = normals[:, 1][np.isfinite(normals[:, 1])]\n",
    "valid_normal_z = normals[:, 2][np.isfinite(normals[:, 2])]\n",
    "\n",
    "distribution_stats = []\n",
    "\n",
    "# --- 1. Angle Change Distribution ---\n",
    "print(\"\\n--- Angle Change Distribution ---\")\n",
    "if len(valid_angle_changes) > 0:\n",
    "    angle_mean = np.mean(valid_angle_changes)\n",
    "    angle_median = np.median(valid_angle_changes)\n",
    "    angle_std = np.std(valid_angle_changes)\n",
    "    angle_min = np.min(valid_angle_changes)\n",
    "    angle_max = np.max(valid_angle_changes)\n",
    "    angle_p25 = np.percentile(valid_angle_changes, 25)\n",
    "    angle_p75 = np.percentile(valid_angle_changes, 75)\n",
    "    angle_p95 = np.percentile(valid_angle_changes, 95)\n",
    "    angle_p99 = np.percentile(valid_angle_changes, 99)\n",
    "    angle_skewness = stats.skew(valid_angle_changes)\n",
    "    angle_kurtosis = stats.kurtosis(valid_angle_changes)\n",
    "    \n",
    "    print(f\"  Count: {len(valid_angle_changes)}\")\n",
    "    print(f\"  Mean: {angle_mean:.4f} deg\")\n",
    "    print(f\"  Median: {angle_median:.4f} deg\")\n",
    "    print(f\"  Std Dev: {angle_std:.4f} deg\")\n",
    "    print(f\"  Min: {angle_min:.4f} deg\")\n",
    "    print(f\"  Max: {angle_max:.4f} deg\")\n",
    "    print(f\"  25th percentile: {angle_p25:.4f} deg\")\n",
    "    print(f\"  75th percentile: {angle_p75:.4f} deg\")\n",
    "    print(f\"  95th percentile: {angle_p95:.4f} deg\")\n",
    "    print(f\"  99th percentile: {angle_p99:.4f} deg\")\n",
    "    print(f\"  Skewness: {angle_skewness:.4f}\")\n",
    "    print(f\"  Kurtosis: {angle_kurtosis:.4f}\")\n",
    "    \n",
    "    distribution_stats.append({\n",
    "        'metric': 'angle_change_deg',\n",
    "        'count': len(valid_angle_changes),\n",
    "        'mean': angle_mean, 'median': angle_median, 'std': angle_std,\n",
    "        'min': angle_min, 'max': angle_max,\n",
    "        'p25': angle_p25, 'p75': angle_p75, 'p95': angle_p95, 'p99': angle_p99,\n",
    "        'skewness': angle_skewness, 'kurtosis': angle_kurtosis\n",
    "    })\n",
    "\n",
    "# --- 2. Angular Velocity Distribution ---\n",
    "print(\"\\n--- Angular Velocity Distribution ---\")\n",
    "if len(valid_angular_velocities) > 0:\n",
    "    vel_mean = np.mean(valid_angular_velocities)\n",
    "    vel_median = np.median(valid_angular_velocities)\n",
    "    vel_std = np.std(valid_angular_velocities)\n",
    "    vel_min = np.min(valid_angular_velocities)\n",
    "    vel_max = np.max(valid_angular_velocities)\n",
    "    vel_p25 = np.percentile(valid_angular_velocities, 25)\n",
    "    vel_p75 = np.percentile(valid_angular_velocities, 75)\n",
    "    vel_p95 = np.percentile(valid_angular_velocities, 95)\n",
    "    vel_p99 = np.percentile(valid_angular_velocities, 99)\n",
    "    vel_skewness = stats.skew(valid_angular_velocities)\n",
    "    vel_kurtosis = stats.kurtosis(valid_angular_velocities)\n",
    "    \n",
    "    print(f\"  Count: {len(valid_angular_velocities)}\")\n",
    "    print(f\"  Mean: {vel_mean:.4f} deg/s\")\n",
    "    print(f\"  Median: {vel_median:.4f} deg/s\")\n",
    "    print(f\"  Std Dev: {vel_std:.4f} deg/s\")\n",
    "    print(f\"  Min: {vel_min:.4f} deg/s\")\n",
    "    print(f\"  Max: {vel_max:.4f} deg/s\")\n",
    "    print(f\"  25th percentile: {vel_p25:.4f} deg/s\")\n",
    "    print(f\"  75th percentile: {vel_p75:.4f} deg/s\")\n",
    "    print(f\"  95th percentile: {vel_p95:.4f} deg/s\")\n",
    "    print(f\"  99th percentile: {vel_p99:.4f} deg/s\")\n",
    "    print(f\"  Skewness: {vel_skewness:.4f}\")\n",
    "    print(f\"  Kurtosis: {vel_kurtosis:.4f}\")\n",
    "    \n",
    "    distribution_stats.append({\n",
    "        'metric': 'angular_velocity_deg_per_s',\n",
    "        'count': len(valid_angular_velocities),\n",
    "        'mean': vel_mean, 'median': vel_median, 'std': vel_std,\n",
    "        'min': vel_min, 'max': vel_max,\n",
    "        'p25': vel_p25, 'p75': vel_p75, 'p95': vel_p95, 'p99': vel_p99,\n",
    "        'skewness': vel_skewness, 'kurtosis': vel_kurtosis\n",
    "    })\n",
    "\n",
    "# --- 3. Normal Vector Component Distributions ---\n",
    "print(\"\\n--- Normal Vector Component Distributions ---\")\n",
    "for comp_name, comp_data in [('normal_x', valid_normal_x), \n",
    "                              ('normal_y', valid_normal_y), \n",
    "                              ('normal_z', valid_normal_z)]:\n",
    "    if len(comp_data) > 0:\n",
    "        comp_mean = np.mean(comp_data)\n",
    "        comp_median = np.median(comp_data)\n",
    "        comp_std = np.std(comp_data)\n",
    "        comp_min = np.min(comp_data)\n",
    "        comp_max = np.max(comp_data)\n",
    "        comp_p25 = np.percentile(comp_data, 25)\n",
    "        comp_p75 = np.percentile(comp_data, 75)\n",
    "        comp_p95 = np.percentile(comp_data, 95)\n",
    "        comp_p99 = np.percentile(comp_data, 99)\n",
    "        comp_skewness = stats.skew(comp_data)\n",
    "        comp_kurtosis = stats.kurtosis(comp_data)\n",
    "        \n",
    "        print(f\"\\n  {comp_name}:\")\n",
    "        print(f\"    Count: {len(comp_data)}\")\n",
    "        print(f\"    Mean: {comp_mean:.6f}\")\n",
    "        print(f\"    Median: {comp_median:.6f}\")\n",
    "        print(f\"    Std Dev: {comp_std:.6f}\")\n",
    "        print(f\"    Min: {comp_min:.6f}, Max: {comp_max:.6f}\")\n",
    "        print(f\"    Range (p25-p75): [{comp_p25:.6f}, {comp_p75:.6f}]\")\n",
    "        print(f\"    Skewness: {comp_skewness:.4f}, Kurtosis: {comp_kurtosis:.4f}\")\n",
    "        \n",
    "        distribution_stats.append({\n",
    "            'metric': comp_name,\n",
    "            'count': len(comp_data),\n",
    "            'mean': comp_mean, 'median': comp_median, 'std': comp_std,\n",
    "            'min': comp_min, 'max': comp_max,\n",
    "            'p25': comp_p25, 'p75': comp_p75, 'p95': comp_p95, 'p99': comp_p99,\n",
    "            'skewness': comp_skewness, 'kurtosis': comp_kurtosis\n",
    "        })\n",
    "\n",
    "# Save distribution statistics\n",
    "dist_stats_df = pd.DataFrame(distribution_stats)\n",
    "dist_out = Path(out_root) / 'distribution_statistics.csv'\n",
    "dist_stats_df.to_csv(dist_out, index=False)\n",
    "print(f\"\\nDistribution statistics saved to: {dist_out}\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== WORST-CASE ANALYSIS =====================\n",
    "# Identifies worst-case scenarios: maximum deviations, outlier frames,\n",
    "# and periods of high instability.\n",
    "# ================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"WORST-CASE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Configuration for outlier detection\n",
    "outlier_std_threshold = 3.0  # Number of standard deviations for outlier detection\n",
    "\n",
    "worst_case_frames = []\n",
    "\n",
    "# --- 1. Maximum Angle Deviation from Mean Normal ---\n",
    "print(\"\\n--- Maximum Angle Deviation from Mean Normal ---\")\n",
    "mean_normal = stability_metrics['mean_normal']\n",
    "if np.all(np.isfinite(mean_normal)):\n",
    "    angles_from_mean = np.full(n_frames, np.nan)\n",
    "    for i in range(n_frames):\n",
    "        if np.all(np.isfinite(normals[i, :])):\n",
    "            angles_from_mean[i] = compute_normal_angle(normals[i, :], mean_normal)\n",
    "    \n",
    "    valid_angles_from_mean = angles_from_mean[np.isfinite(angles_from_mean)]\n",
    "    if len(valid_angles_from_mean) > 0:\n",
    "        max_deviation_idx = np.nanargmax(angles_from_mean)\n",
    "        max_deviation = angles_from_mean[max_deviation_idx]\n",
    "        max_deviation_time = times[max_deviation_idx]\n",
    "        \n",
    "        print(f\"  Maximum deviation: {max_deviation:.4f} degrees\")\n",
    "        print(f\"  Frame: {frames[max_deviation_idx]}\")\n",
    "        print(f\"  Time: {max_deviation_time:.4f} s\")\n",
    "        \n",
    "        worst_case_frames.append({\n",
    "            'frame': frames[max_deviation_idx],\n",
    "            'time_s': max_deviation_time,\n",
    "            'type': 'max_deviation_from_mean',\n",
    "            'value_deg': max_deviation,\n",
    "            'description': 'Maximum angle deviation from mean normal vector'\n",
    "        })\n",
    "\n",
    "# --- 2. Outlier Frame Detection (angle changes > 3 std) ---\n",
    "print(f\"\\n--- Outlier Frame Detection (>{outlier_std_threshold} std) ---\")\n",
    "if len(valid_angle_changes) > 0:\n",
    "    angle_mean = np.mean(valid_angle_changes)\n",
    "    angle_std = np.std(valid_angle_changes)\n",
    "    outlier_threshold = angle_mean + outlier_std_threshold * angle_std\n",
    "    \n",
    "    print(f\"  Mean angle change: {angle_mean:.4f} deg\")\n",
    "    print(f\"  Std dev: {angle_std:.4f} deg\")\n",
    "    print(f\"  Outlier threshold (>{outlier_std_threshold} std): {outlier_threshold:.4f} deg\")\n",
    "    \n",
    "    outlier_mask = angle_changes > outlier_threshold\n",
    "    outlier_indices = np.where(outlier_mask)[0]\n",
    "    \n",
    "    print(f\"  Number of outlier frames: {len(outlier_indices)}\")\n",
    "    \n",
    "    if len(outlier_indices) > 0:\n",
    "        print(f\"\\n  Top 10 outlier frames:\")\n",
    "        # Sort by angle change descending\n",
    "        sorted_outliers = sorted(outlier_indices, key=lambda x: angle_changes[x], reverse=True)\n",
    "        for idx in sorted_outliers[:10]:\n",
    "            print(f\"    Frame {frames[idx]}: {angle_changes[idx]:.4f} deg at t={times[idx]:.4f}s\")\n",
    "            worst_case_frames.append({\n",
    "                'frame': frames[idx],\n",
    "                'time_s': times[idx],\n",
    "                'type': 'outlier_angle_change',\n",
    "                'value_deg': angle_changes[idx],\n",
    "                'description': f'Angle change exceeds {outlier_std_threshold} std ({outlier_threshold:.2f} deg)'\n",
    "            })\n",
    "\n",
    "# --- 3. Unstable Time Periods ---\n",
    "print(\"\\n--- Unstable Time Periods ---\")\n",
    "# Find contiguous periods where stability std exceeds threshold\n",
    "unstable_mask = normals_stability_std >= stability_threshold_deg\n",
    "unstable_indices = np.where(unstable_mask)[0]\n",
    "\n",
    "if len(unstable_indices) > 0:\n",
    "    # Find contiguous regions\n",
    "    unstable_periods = []\n",
    "    period_start = unstable_indices[0]\n",
    "    period_end = unstable_indices[0]\n",
    "    \n",
    "    for i in range(1, len(unstable_indices)):\n",
    "        if unstable_indices[i] == unstable_indices[i-1] + 1:\n",
    "            period_end = unstable_indices[i]\n",
    "        else:\n",
    "            # Save previous period\n",
    "            unstable_periods.append((period_start, period_end))\n",
    "            period_start = unstable_indices[i]\n",
    "            period_end = unstable_indices[i]\n",
    "    # Save last period\n",
    "    unstable_periods.append((period_start, period_end))\n",
    "    \n",
    "    print(f\"  Number of unstable periods: {len(unstable_periods)}\")\n",
    "    \n",
    "    # Sort by duration (longest first)\n",
    "    unstable_periods_sorted = sorted(unstable_periods, key=lambda x: x[1] - x[0], reverse=True)\n",
    "    \n",
    "    print(f\"\\n  Top 10 longest unstable periods:\")\n",
    "    for start_idx, end_idx in unstable_periods_sorted[:10]:\n",
    "        duration_frames = end_idx - start_idx + 1\n",
    "        duration_s = duration_frames / fps\n",
    "        start_time = times[start_idx] if start_idx < len(times) else np.nan\n",
    "        end_time = times[end_idx] if end_idx < len(times) else np.nan\n",
    "        max_std_in_period = np.nanmax(normals_stability_std[start_idx:end_idx+1])\n",
    "        \n",
    "        print(f\"    {start_time:.3f}s - {end_time:.3f}s ({duration_s:.3f}s, {duration_frames} frames, max std: {max_std_in_period:.2f} deg)\")\n",
    "        \n",
    "        worst_case_frames.append({\n",
    "            'frame': frames[start_idx],\n",
    "            'time_s': start_time,\n",
    "            'type': 'unstable_period_start',\n",
    "            'value_deg': max_std_in_period,\n",
    "            'description': f'Unstable period: {start_time:.3f}s-{end_time:.3f}s ({duration_s:.3f}s duration)'\n",
    "        })\n",
    "else:\n",
    "    print(\"  No unstable periods detected.\")\n",
    "\n",
    "# --- 4. Frames with Maximum Angular Velocity ---\n",
    "print(\"\\n--- Maximum Angular Velocity Frames ---\")\n",
    "if len(valid_angular_velocities) > 0:\n",
    "    top_velocity_indices = np.argsort(angular_velocities)[::-1][:10]  # Top 10\n",
    "    print(\"  Top 10 frames by angular velocity:\")\n",
    "    for idx in top_velocity_indices:\n",
    "        if np.isfinite(angular_velocities[idx]):\n",
    "            print(f\"    Frame {frames[idx]}: {angular_velocities[idx]:.4f} deg/s at t={times[idx]:.4f}s\")\n",
    "            if angular_velocities[idx] == np.nanmax(angular_velocities):\n",
    "                worst_case_frames.append({\n",
    "                    'frame': frames[idx],\n",
    "                    'time_s': times[idx],\n",
    "                    'type': 'max_angular_velocity',\n",
    "                    'value_deg': angular_velocities[idx],\n",
    "                    'description': 'Maximum angular velocity'\n",
    "                })\n",
    "\n",
    "# Save worst-case frames\n",
    "worst_case_df = pd.DataFrame(worst_case_frames)\n",
    "worst_case_out = Path(out_root) / 'worst_case_frames.csv'\n",
    "worst_case_df.to_csv(worst_case_out, index=False)\n",
    "print(f\"\\nWorst-case frames saved to: {worst_case_out}\")\n",
    "print(f\"Total worst-case events identified: {len(worst_case_frames)}\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== NOSE POINT (NODE_3) STABILITY ANALYSIS =====================\n",
    "# Analyzes the positional stability of the nose point (node_3) across all frames.\n",
    "# Computes displacement from mean position, frame-to-frame movement, and rolling\n",
    "# stability metrics.\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"NOSE POINT (NODE_3) STABILITY ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Configuration\n",
    "nose_node_name = 'node_3'  # Nose point node name\n",
    "\n",
    "# Find nose node index\n",
    "nose_node_idx = None\n",
    "for i, n in enumerate(nodes):\n",
    "    if n == nose_node_name:\n",
    "        nose_node_idx = i\n",
    "        break\n",
    "\n",
    "if nose_node_idx is None:\n",
    "    print(f\"Error: Could not find nose node '{nose_node_name}' in the data.\")\n",
    "    print(f\"Available nodes: {nodes}\")\n",
    "else:\n",
    "    print(f\"Nose node: {nose_node_name} (index: {nose_node_idx})\")\n",
    "    \n",
    "    # Extract nose point positions\n",
    "    nose_positions = X3[:, nose_node_idx, :]  # (n_frames, 3)\n",
    "    \n",
    "    # Count valid frames\n",
    "    valid_nose_mask = np.all(np.isfinite(nose_positions), axis=1)\n",
    "    valid_nose_count = np.sum(valid_nose_mask)\n",
    "    print(f\"Valid nose point frames: {valid_nose_count} / {n_frames}\")\n",
    "    \n",
    "    # --- 1. Mean Position and Displacement from Mean ---\n",
    "    print(\"\\n--- Mean Position and Displacement ---\")\n",
    "    valid_nose_positions = nose_positions[valid_nose_mask]\n",
    "    \n",
    "    if len(valid_nose_positions) > 0:\n",
    "        mean_nose_position = np.mean(valid_nose_positions, axis=0)\n",
    "        print(f\"  Mean position: [{mean_nose_position[0]:.4f}, {mean_nose_position[1]:.4f}, {mean_nose_position[2]:.4f}]\")\n",
    "        \n",
    "        # Displacement from mean for each frame\n",
    "        displacement_from_mean = np.full(n_frames, np.nan)\n",
    "        displacement_x = np.full(n_frames, np.nan)\n",
    "        displacement_y = np.full(n_frames, np.nan)\n",
    "        displacement_z = np.full(n_frames, np.nan)\n",
    "        \n",
    "        for i in range(n_frames):\n",
    "            if np.all(np.isfinite(nose_positions[i, :])):\n",
    "                diff = nose_positions[i, :] - mean_nose_position\n",
    "                displacement_from_mean[i] = np.linalg.norm(diff)\n",
    "                displacement_x[i] = diff[0]\n",
    "                displacement_y[i] = diff[1]\n",
    "                displacement_z[i] = diff[2]\n",
    "        \n",
    "        valid_displacements = displacement_from_mean[np.isfinite(displacement_from_mean)]\n",
    "        print(f\"  Mean displacement from mean: {np.mean(valid_displacements):.4f}\")\n",
    "        print(f\"  Max displacement from mean: {np.max(valid_displacements):.4f}\")\n",
    "        print(f\"  Std dev of displacement: {np.std(valid_displacements):.4f}\")\n",
    "        \n",
    "        # Find frame with maximum displacement\n",
    "        max_disp_idx = np.nanargmax(displacement_from_mean)\n",
    "        print(f\"  Max displacement frame: {frames[max_disp_idx]} at t={times[max_disp_idx]:.4f}s\")\n",
    "    \n",
    "    # --- 2. Frame-to-Frame Displacement ---\n",
    "    print(\"\\n--- Frame-to-Frame Displacement ---\")\n",
    "    frame_to_frame_disp = np.full(n_frames, np.nan)\n",
    "    \n",
    "    for i in range(1, n_frames):\n",
    "        if np.all(np.isfinite(nose_positions[i, :])) and np.all(np.isfinite(nose_positions[i-1, :])):\n",
    "            diff = nose_positions[i, :] - nose_positions[i-1, :]\n",
    "            frame_to_frame_disp[i] = np.linalg.norm(diff)\n",
    "    \n",
    "    valid_f2f_disp = frame_to_frame_disp[np.isfinite(frame_to_frame_disp)]\n",
    "    if len(valid_f2f_disp) > 0:\n",
    "        print(f\"  Mean frame-to-frame displacement: {np.mean(valid_f2f_disp):.4f}\")\n",
    "        print(f\"  Max frame-to-frame displacement: {np.max(valid_f2f_disp):.4f}\")\n",
    "        print(f\"  Std dev: {np.std(valid_f2f_disp):.4f}\")\n",
    "        \n",
    "        # Velocity (displacement per second)\n",
    "        nose_velocity = frame_to_frame_disp * fps\n",
    "        valid_velocities = nose_velocity[np.isfinite(nose_velocity)]\n",
    "        print(f\"  Mean velocity: {np.mean(valid_velocities):.4f} units/s\")\n",
    "        print(f\"  Max velocity: {np.max(valid_velocities):.4f} units/s\")\n",
    "    \n",
    "    # --- 3. Rolling Position Stability (1s window) ---\n",
    "    print(\"\\n--- Rolling Position Stability (1s window) ---\")\n",
    "    nose_rolling_std = np.full(n_frames, np.nan)\n",
    "    \n",
    "    for i in range(n_frames):\n",
    "        start = max(0, i - window_1s // 2)\n",
    "        end = min(n_frames, i + window_1s // 2 + 1)\n",
    "        window_positions = nose_positions[start:end, :]\n",
    "        valid_window = np.all(np.isfinite(window_positions), axis=1)\n",
    "        \n",
    "        if np.sum(valid_window) > 1:\n",
    "            valid_pos = window_positions[valid_window]\n",
    "            # Compute std of distances from window mean\n",
    "            window_mean = np.mean(valid_pos, axis=0)\n",
    "            distances = np.linalg.norm(valid_pos - window_mean, axis=1)\n",
    "            nose_rolling_std[i] = np.std(distances)\n",
    "    \n",
    "    valid_rolling_std = nose_rolling_std[np.isfinite(nose_rolling_std)]\n",
    "    if len(valid_rolling_std) > 0:\n",
    "        print(f\"  Mean rolling std: {np.mean(valid_rolling_std):.4f}\")\n",
    "        print(f\"  Max rolling std: {np.max(valid_rolling_std):.4f}\")\n",
    "        \n",
    "        # Find periods of high movement\n",
    "        high_movement_threshold = np.mean(valid_rolling_std) + 2 * np.std(valid_rolling_std)\n",
    "        high_movement_mask = nose_rolling_std > high_movement_threshold\n",
    "        high_movement_count = np.sum(high_movement_mask)\n",
    "        high_movement_percent = 100 * high_movement_count / n_frames\n",
    "        print(f\"  High movement threshold: {high_movement_threshold:.4f}\")\n",
    "        print(f\"  High movement frames: {high_movement_count} ({high_movement_percent:.2f}%)\")\n",
    "    \n",
    "    # --- 4. Nose Point Stability Summary ---\n",
    "    print(\"\\n--- Nose Point Stability Summary ---\")\n",
    "    \n",
    "    # Classify nose stability\n",
    "    if len(valid_rolling_std) > 0:\n",
    "        stable_nose_threshold = np.median(valid_rolling_std) + np.std(valid_rolling_std)\n",
    "        stable_nose_count = np.sum(nose_rolling_std <= stable_nose_threshold)\n",
    "        stable_nose_percent = 100 * stable_nose_count / n_frames\n",
    "        print(f\"  Stable nose frames (<= {stable_nose_threshold:.4f}): {stable_nose_count} ({stable_nose_percent:.2f}%)\")\n",
    "    \n",
    "    # --- 5. Create and Save Nose Point Stability DataFrame ---\n",
    "    nose_results = []\n",
    "    for i in range(n_frames):\n",
    "        nose_results.append({\n",
    "            'frame': frames[i],\n",
    "            'time_s': times[i],\n",
    "            'nose_x': nose_positions[i, 0] if np.isfinite(nose_positions[i, 0]) else np.nan,\n",
    "            'nose_y': nose_positions[i, 1] if np.isfinite(nose_positions[i, 1]) else np.nan,\n",
    "            'nose_z': nose_positions[i, 2] if np.isfinite(nose_positions[i, 2]) else np.nan,\n",
    "            'displacement_from_mean': displacement_from_mean[i] if np.isfinite(displacement_from_mean[i]) else np.nan,\n",
    "            'displacement_x': displacement_x[i] if np.isfinite(displacement_x[i]) else np.nan,\n",
    "            'displacement_y': displacement_y[i] if np.isfinite(displacement_y[i]) else np.nan,\n",
    "            'displacement_z': displacement_z[i] if np.isfinite(displacement_z[i]) else np.nan,\n",
    "            'frame_to_frame_disp': frame_to_frame_disp[i] if np.isfinite(frame_to_frame_disp[i]) else np.nan,\n",
    "            'velocity_units_per_s': nose_velocity[i] if np.isfinite(nose_velocity[i]) else np.nan,\n",
    "            'rolling_std_1s': nose_rolling_std[i] if np.isfinite(nose_rolling_std[i]) else np.nan,\n",
    "        })\n",
    "    \n",
    "    nose_df = pd.DataFrame(nose_results)\n",
    "    nose_out = Path(out_root) / 'nose_point_stability.csv'\n",
    "    nose_df.to_csv(nose_out, index=False)\n",
    "    print(f\"\\nNose point stability analysis saved to: {nose_out}\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"[NOSE POINT ANALYSIS COMPLETE]\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}