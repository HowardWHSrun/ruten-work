{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 3 - Normal Vector Stability Analysis\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook analyzes the stability of normal vectors computed from a reference plane defined by 3 landmark nodes. It quantifies stability metrics, measures directional changes over time, and provides longer-period state estimates.\n",
        "\n",
        "## What This Analysis Does\n",
        "\n",
        "The analysis computes plane normal vectors from 3 landmark points (typically head landmarks) and measures:\n",
        "1. **Normal Vector Stability**: How stable the plane orientation is over time\n",
        "2. **Angle Changes**: Frame-to-frame angular changes in the normal vector direction\n",
        "3. **Angular Velocity**: Rate of change of normal vector direction\n",
        "4. **Rolling Statistics**: Mean normal vectors over different time windows (0.5s, 1s, 5s)\n",
        "5. **State Classification**: Classifies each frame as \"stable\" or \"changing\" based on stability metrics\n",
        "6. **Per-Second Analysis**: Mean normal vector per second and angle shifts between seconds\n",
        "\n",
        "## Methodology\n",
        "\n",
        "### 1. Plane Normal Computation\n",
        "- For each frame, compute the plane normal vector from 3 landmark points using cross product\n",
        "- Normalize the vector to unit length\n",
        "- The normal vector represents the orientation of the reference plane\n",
        "\n",
        "### 2. Angle Change Metrics\n",
        "- **Frame-to-frame angle change**: Angle between consecutive normal vectors\n",
        "- **Cumulative angle change**: Total angle change from the first valid frame\n",
        "- **Angular velocity**: Rate of change in degrees per second\n",
        "\n",
        "### 3. Rolling Statistics\n",
        "- Compute rolling mean normal vectors over windows of 0.5s, 1s, and 5s\n",
        "- Compute rolling standard deviation of angles from the rolling mean\n",
        "- These provide smoothed estimates of normal vector direction\n",
        "\n",
        "### 4. Low-Pass Filtering\n",
        "- Apply Butterworth low-pass filter (5 Hz cutoff) to reduce high-frequency noise\n",
        "- Helps separate real directional changes from tracking noise\n",
        "\n",
        "### 5. State Classification\n",
        "- Classify frames as \"stable\" or \"changing\" based on rolling standard deviation\n",
        "- Threshold: < 5 degrees = stable, >= 5 degrees = changing\n",
        "\n",
        "### 6. Per-Second Block Analysis\n",
        "- Compute mean normal vector for each 1-second block\n",
        "- Compute angle shift between consecutive seconds\n",
        "- Enforces continuity to avoid 180-degree jumps\n",
        "\n",
        "## Outputs\n",
        "\n",
        "- `normal_vector_stability_analysis.csv`: Frame-by-frame results with all metrics\n",
        "- `normal_vector_stability_sec_blocks.csv`: Per-second block analysis with angle shifts\n",
        "- Summary statistics printed to console\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === PHASE 3 â€¢ NORMAL VECTOR STABILITY ANALYSIS ============================\n",
        "# Analyzes the stability of normal vectors computed from a reference plane\n",
        "# defined by 3 landmark nodes.\n",
        "#\n",
        "# INPUT:\n",
        "#   csv_path: Path to CSV file with 3D node data (columns: frame, node, x, y, z, time_s)\n",
        "#   fps: Frames per second (default 120.0)\n",
        "#   landmark_nodes: List of 3 node names to use for plane computation\n",
        "#\n",
        "# OUTPUT:\n",
        "#   normal_vector_stability_analysis.csv: Frame-by-frame results\n",
        "#   normal_vector_stability_sec_blocks.csv: Per-second block analysis\n",
        "# ============================================================================\n",
        "\n",
        "# ===================== USER CONFIGURATION =====================\n",
        "csv_path = r\"data/processed/all_nodes_3d_long (1).csv\"  # Path to 3D node data CSV\n",
        "fps = 120.0  # Frames per second\n",
        "landmark_nodes = ['node_1', 'node_2', 'node_3']  # 3 nodes to define reference plane\n",
        "\n",
        "# Output directory\n",
        "out_root = \"results\"  # Output directory for results\n",
        "\n",
        "# Analysis parameters\n",
        "stability_threshold_deg = 5.0  # Threshold for stable/changing classification (degrees)\n",
        "lowpass_cutoff_hz = 5.0  # Low-pass filter cutoff frequency (Hz)\n",
        "# ==============================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from scipy import signal\n",
        "import os\n",
        "\n",
        "os.makedirs(out_root, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===================== HELPER FUNCTIONS =====================\n",
        "\n",
        "def load_and_structure_data(csv_path):\n",
        "    \"\"\"Load CSV data and convert to structured array format\"\"\"\n",
        "    print(\"Loading data...\")\n",
        "    df = pd.read_csv(csv_path)\n",
        "    \n",
        "    # Get frames and nodes\n",
        "    frames = df['frame'].unique()\n",
        "    nodes = df['node'].unique()\n",
        "    print(f\"Frames: {len(frames)}, Nodes: {len(nodes)}\")\n",
        "    print(f\"Nodes: {nodes}\")\n",
        "    \n",
        "    # Prepare data array: frames x nodes x coordinates\n",
        "    n_frames = len(frames)\n",
        "    n_nodes = len(nodes)\n",
        "    X3 = np.full((n_frames, n_nodes, 3), np.nan)\n",
        "    \n",
        "    # Fill the array\n",
        "    for i, node in enumerate(nodes):\n",
        "        node_data = df[df['node'] == node]\n",
        "        for _, row in node_data.iterrows():\n",
        "            frame_idx = int(row['frame'])\n",
        "            if frame_idx < n_frames:\n",
        "                X3[frame_idx, i, 0] = row['x'] if pd.notna(row['x']) else np.nan\n",
        "                X3[frame_idx, i, 1] = row['y'] if pd.notna(row['y']) else np.nan\n",
        "                X3[frame_idx, i, 2] = row['z'] if pd.notna(row['z']) else np.nan\n",
        "    \n",
        "    # Get time array\n",
        "    times = df[df['node'] == nodes[0]]['time_s'].values\n",
        "    \n",
        "    return X3, frames, nodes, times\n",
        "\n",
        "\n",
        "def find_node_indices(nodes, target_nodes):\n",
        "    \"\"\"Find indices of target nodes in the nodes array\"\"\"\n",
        "    indices = []\n",
        "    for target in target_nodes:\n",
        "        for i, n in enumerate(nodes):\n",
        "            if n == target:\n",
        "                indices.append(i)\n",
        "                break\n",
        "    return indices\n",
        "\n",
        "\n",
        "def compute_plane_normal(X3, frame, landmark_indices):\n",
        "    \"\"\"\n",
        "    Compute plane normal vector from 3 landmark points\n",
        "    \n",
        "    Args:\n",
        "        X3: Data array (frames x nodes x coordinates)\n",
        "        frame: Current frame index\n",
        "        landmark_indices: Indices of 3 landmark nodes\n",
        "    \n",
        "    Returns:\n",
        "        normal: Normalized plane normal vector (3D) or None if invalid\n",
        "    \"\"\"\n",
        "    # Extract landmark positions\n",
        "    p1 = X3[frame, landmark_indices[0], :]\n",
        "    p2 = X3[frame, landmark_indices[1], :]\n",
        "    p3 = X3[frame, landmark_indices[2], :]\n",
        "    \n",
        "    # Check if all points are valid\n",
        "    if not (np.all(np.isfinite(p1)) and np.all(np.isfinite(p2)) and np.all(np.isfinite(p3))):\n",
        "        return None\n",
        "    \n",
        "    # Calculate plane normal via cross product\n",
        "    v1 = p2 - p1\n",
        "    v2 = p3 - p1\n",
        "    normal = np.cross(v1, v2)\n",
        "    norm_mag = np.linalg.norm(normal)\n",
        "    \n",
        "    if norm_mag < 1e-10:\n",
        "        return None\n",
        "    \n",
        "    normal = normal / norm_mag  # Normalize\n",
        "    \n",
        "    return normal\n",
        "\n",
        "\n",
        "def compute_normal_angle(n1, n2):\n",
        "    \"\"\"\n",
        "    Compute angle between two normal vectors in degrees\n",
        "    \n",
        "    Args:\n",
        "        n1, n2: Normalized normal vectors (3D arrays)\n",
        "    \n",
        "    Returns:\n",
        "        angle: Angle in degrees (0-180)\n",
        "    \"\"\"\n",
        "    if n1 is None or n2 is None:\n",
        "        return np.nan\n",
        "    \n",
        "    if not (np.all(np.isfinite(n1)) and np.all(np.isfinite(n2))):\n",
        "        return np.nan\n",
        "    \n",
        "    # Dot product (clamped to handle numerical errors)\n",
        "    dot_product = np.clip(np.dot(n1, n2), -1.0, 1.0)\n",
        "    angle_rad = np.arccos(dot_product)\n",
        "    angle_deg = np.degrees(angle_rad)\n",
        "    \n",
        "    return angle_deg\n",
        "\n",
        "\n",
        "def rolling_statistics(data, window_size_frames, func=np.mean, fill_value=np.nan):\n",
        "    \"\"\"\n",
        "    Compute rolling statistics over a window\n",
        "    \n",
        "    Args:\n",
        "        data: 1D or 2D array\n",
        "        window_size_frames: Window size in frames\n",
        "        func: Function to apply (np.mean, np.std, etc.)\n",
        "        fill_value: Value to use for insufficient data\n",
        "    \n",
        "    Returns:\n",
        "        Rolling statistics array\n",
        "    \"\"\"\n",
        "    if len(data) == 0:\n",
        "        return np.array([])\n",
        "    \n",
        "    # Handle 2D arrays (for vector data)\n",
        "    if data.ndim == 2:\n",
        "        n_frames, n_dims = data.shape\n",
        "        result = np.full((n_frames, n_dims), fill_value)\n",
        "        for i in range(n_frames):\n",
        "            start = max(0, i - window_size_frames // 2)\n",
        "            end = min(n_frames, i + window_size_frames // 2 + 1)\n",
        "            window_data = data[start:end, :]\n",
        "            valid_mask = np.all(np.isfinite(window_data), axis=1)\n",
        "            if np.sum(valid_mask) > 0:\n",
        "                result[i, :] = func(window_data[valid_mask], axis=0)\n",
        "    else:\n",
        "        # Handle 1D arrays\n",
        "        n_frames = len(data)\n",
        "        result = np.full(n_frames, fill_value)\n",
        "        for i in range(n_frames):\n",
        "            start = max(0, i - window_size_frames // 2)\n",
        "            end = min(n_frames, i + window_size_frames // 2 + 1)\n",
        "            window_data = data[start:end]\n",
        "            valid_mask = np.isfinite(window_data)\n",
        "            if np.sum(valid_mask) > 0:\n",
        "                result[i] = func(window_data[valid_mask])\n",
        "    \n",
        "    return result\n",
        "\n",
        "\n",
        "def apply_lowpass_filter(data, fps, cutoff_hz=5.0, order=4):\n",
        "    \"\"\"\n",
        "    Apply Butterworth low-pass filter to reduce high-frequency noise\n",
        "    \n",
        "    Args:\n",
        "        data: 2D array (n_frames x n_dims)\n",
        "        fps: Frames per second\n",
        "        cutoff_hz: Cutoff frequency in Hz\n",
        "        order: Filter order\n",
        "    \n",
        "    Returns:\n",
        "        Filtered data\n",
        "    \"\"\"\n",
        "    if len(data) == 0:\n",
        "        return data\n",
        "    \n",
        "    nyquist = fps / 2.0\n",
        "    if cutoff_hz >= nyquist:\n",
        "        cutoff_hz = nyquist * 0.95  # Ensure below Nyquist\n",
        "    \n",
        "    b, a = signal.butter(order, cutoff_hz / nyquist, btype='low')\n",
        "    \n",
        "    # Filter each dimension separately\n",
        "    filtered = np.full_like(data, np.nan)\n",
        "    for dim in range(data.shape[1]):\n",
        "        valid_mask = np.isfinite(data[:, dim])\n",
        "        if np.sum(valid_mask) > order * 2:  # Need enough points for filter\n",
        "            filtered_data = signal.filtfilt(b, a, data[valid_mask, dim])\n",
        "            filtered[valid_mask, dim] = filtered_data\n",
        "    \n",
        "    return filtered\n",
        "\n",
        "\n",
        "def compute_stability_metrics(normals):\n",
        "    \"\"\"\n",
        "    Compute overall stability metrics for normal vectors\n",
        "    \n",
        "    Args:\n",
        "        normals: Array of normal vectors (n_frames x 3)\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary with stability metrics\n",
        "    \"\"\"\n",
        "    # Filter out invalid normals\n",
        "    valid_mask = np.all(np.isfinite(normals), axis=1)\n",
        "    valid_normals = normals[valid_mask]\n",
        "    \n",
        "    if len(valid_normals) == 0:\n",
        "        return {\n",
        "            'mean_normal': np.array([np.nan, np.nan, np.nan]),\n",
        "            'std_components': np.array([np.nan, np.nan, np.nan]),\n",
        "            'mean_angular_dispersion': np.nan,\n",
        "            'coefficient_of_variation': np.nan\n",
        "        }\n",
        "    \n",
        "    # Mean normal vector\n",
        "    mean_normal = np.mean(valid_normals, axis=0)\n",
        "    mean_normal = mean_normal / np.linalg.norm(mean_normal)  # Normalize\n",
        "    \n",
        "    # Standard deviation of components\n",
        "    std_components = np.std(valid_normals, axis=0)\n",
        "    \n",
        "    # Angular dispersion: std dev of angles from mean normal\n",
        "    angles_from_mean = []\n",
        "    for n in valid_normals:\n",
        "        angle = compute_normal_angle(n, mean_normal)\n",
        "        if not np.isnan(angle):\n",
        "            angles_from_mean.append(angle)\n",
        "    \n",
        "    mean_angular_dispersion = np.std(angles_from_mean) if len(angles_from_mean) > 0 else np.nan\n",
        "    \n",
        "    # Coefficient of variation for normal magnitude (should be ~0 for unit vectors)\n",
        "    magnitudes = np.linalg.norm(valid_normals, axis=1)\n",
        "    mean_magnitude = np.mean(magnitudes)\n",
        "    std_magnitude = np.std(magnitudes)\n",
        "    coefficient_of_variation = (std_magnitude / mean_magnitude) if mean_magnitude > 0 else np.nan\n",
        "    \n",
        "    return {\n",
        "        'mean_normal': mean_normal,\n",
        "        'std_components': std_components,\n",
        "        'mean_angular_dispersion': mean_angular_dispersion,\n",
        "        'coefficient_of_variation': coefficient_of_variation\n",
        "    }\n",
        "\n",
        "\n",
        "def classify_state(normals_stability_std, threshold=5.0):\n",
        "    \"\"\"\n",
        "    Classify each frame as stable or changing based on rolling standard deviation\n",
        "    \n",
        "    Args:\n",
        "        normals_stability_std: Rolling standard deviation values\n",
        "        threshold: Threshold in degrees for classification\n",
        "    \n",
        "    Returns:\n",
        "        Array of state labels ('stable' or 'changing')\n",
        "    \"\"\"\n",
        "    states = np.full(len(normals_stability_std), 'changing', dtype=object)\n",
        "    valid_mask = np.isfinite(normals_stability_std)\n",
        "    states[valid_mask & (normals_stability_std < threshold)] = 'stable'\n",
        "    \n",
        "    return states\n",
        "# ==============================================================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===================== MAIN ANALYSIS =====================\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"Normal Vector Stability Analysis\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "dt = 1.0 / fps\n",
        "\n",
        "# Window sizes in frames\n",
        "window_0_5s = int(0.5 * fps)  # 60 frames\n",
        "window_1s = int(1.0 * fps)    # 120 frames\n",
        "window_5s = int(5.0 * fps)    # 600 frames\n",
        "window_10s = int(10.0 * fps)  # 1200 frames\n",
        "\n",
        "# Load data\n",
        "X3, frames, nodes, times = load_and_structure_data(csv_path)\n",
        "\n",
        "# Find landmark indices\n",
        "landmark_indices = find_node_indices(nodes, landmark_nodes)\n",
        "if len(landmark_indices) != 3:\n",
        "    print(f\"Error: Could not find all landmarks. Expected {landmark_nodes}\")\n",
        "    print(f\"Found indices: {landmark_indices}\")\n",
        "    raise RuntimeError(f\"Could not find all landmarks: {landmark_nodes}\")\n",
        "\n",
        "print(f\"\\nLandmark nodes: {landmark_nodes}\")\n",
        "print(f\"Landmark indices: {landmark_indices}\")\n",
        "\n",
        "n_frames = len(frames)\n",
        "\n",
        "# Compute normal vectors for all frames\n",
        "print(\"\\nComputing normal vectors...\")\n",
        "normals = np.full((n_frames, 3), np.nan)\n",
        "\n",
        "for i in range(n_frames):\n",
        "    normal = compute_plane_normal(X3, i, landmark_indices)\n",
        "    if normal is not None:\n",
        "        normals[i, :] = normal\n",
        "\n",
        "valid_normal_count = np.sum(np.all(np.isfinite(normals), axis=1))\n",
        "print(f\"Computed {valid_normal_count} valid normal vectors out of {n_frames} frames\")\n",
        "\n",
        "# Compute angle changes\n",
        "print(\"\\nComputing angle changes...\")\n",
        "angle_changes = np.full(n_frames, np.nan)\n",
        "cumulative_angle_changes = np.full(n_frames, np.nan)\n",
        "angular_velocities = np.full(n_frames, np.nan)\n",
        "\n",
        "for i in range(1, n_frames):\n",
        "    if np.all(np.isfinite(normals[i, :])) and np.all(np.isfinite(normals[i-1, :])):\n",
        "        angle = compute_normal_angle(normals[i-1, :], normals[i, :])\n",
        "        angle_changes[i] = angle\n",
        "        \n",
        "        # Angular velocity (degrees per second)\n",
        "        if not np.isnan(angle):\n",
        "            angular_velocities[i] = angle / dt\n",
        "\n",
        "# Cumulative angle change from first frame\n",
        "cumulative_angle = 0.0\n",
        "first_valid_idx = None\n",
        "for i in range(n_frames):\n",
        "    if np.all(np.isfinite(normals[i, :])):\n",
        "        if first_valid_idx is None:\n",
        "            first_valid_idx = i\n",
        "            cumulative_angle_changes[i] = 0.0\n",
        "        elif first_valid_idx is not None:\n",
        "            angle = compute_normal_angle(normals[first_valid_idx, :], normals[i, :])\n",
        "            if not np.isnan(angle):\n",
        "                cumulative_angle = angle\n",
        "                cumulative_angle_changes[i] = cumulative_angle\n",
        "\n",
        "# Rolling statistics\n",
        "print(\"\\nComputing rolling statistics...\")\n",
        "\n",
        "# Rolling mean normal vectors (0.5s, 1s, 5s windows)\n",
        "rolling_mean_0_5s = rolling_statistics(normals, window_0_5s, func=np.mean)\n",
        "rolling_mean_1s = rolling_statistics(normals, window_1s, func=np.mean)\n",
        "rolling_mean_5s = rolling_statistics(normals, window_5s, func=np.mean)\n",
        "\n",
        "# Normalize rolling means\n",
        "for i in range(n_frames):\n",
        "    if np.all(np.isfinite(rolling_mean_0_5s[i, :])):\n",
        "        rolling_mean_0_5s[i, :] = rolling_mean_0_5s[i, :] / np.linalg.norm(rolling_mean_0_5s[i, :])\n",
        "    if np.all(np.isfinite(rolling_mean_1s[i, :])):\n",
        "        rolling_mean_1s[i, :] = rolling_mean_1s[i, :] / np.linalg.norm(rolling_mean_1s[i, :])\n",
        "    if np.all(np.isfinite(rolling_mean_5s[i, :])):\n",
        "        rolling_mean_5s[i, :] = rolling_mean_5s[i, :] / np.linalg.norm(rolling_mean_5s[i, :])\n",
        "\n",
        "# Rolling standard deviation of angles (using 1s window)\n",
        "reference_normal = rolling_mean_1s\n",
        "normals_stability_std = np.full(n_frames, np.nan)\n",
        "normals_stability_mean_angle = np.full(n_frames, np.nan)\n",
        "\n",
        "for i in range(n_frames):\n",
        "    if np.all(np.isfinite(normals[i, :])) and np.all(np.isfinite(reference_normal[i, :])):\n",
        "        # Angle from current normal to rolling mean\n",
        "        angle = compute_normal_angle(normals[i, :], reference_normal[i, :])\n",
        "        normals_stability_mean_angle[i] = angle\n",
        "        \n",
        "        # Rolling std of angles in window\n",
        "        start = max(0, i - window_1s // 2)\n",
        "        end = min(n_frames, i + window_1s // 2 + 1)\n",
        "        window_angles = normals_stability_mean_angle[start:end]\n",
        "        valid_angles = window_angles[np.isfinite(window_angles)]\n",
        "        if len(valid_angles) > 1:\n",
        "            normals_stability_std[i] = np.std(valid_angles)\n",
        "\n",
        "# Low-pass filtered normals\n",
        "print(\"Applying low-pass filter...\")\n",
        "filtered_normals = apply_lowpass_filter(normals, fps, cutoff_hz=lowpass_cutoff_hz)\n",
        "# Normalize filtered normals\n",
        "for i in range(n_frames):\n",
        "    if np.all(np.isfinite(filtered_normals[i, :])):\n",
        "        filtered_normals[i, :] = filtered_normals[i, :] / np.linalg.norm(filtered_normals[i, :])\n",
        "\n",
        "# State classification\n",
        "print(\"Classifying states...\")\n",
        "state_labels = classify_state(normals_stability_std, threshold=stability_threshold_deg)\n",
        "\n",
        "# Overall stability metrics\n",
        "print(\"\\nComputing overall stability metrics...\")\n",
        "stability_metrics = compute_stability_metrics(normals)\n",
        "\n",
        "# Create output DataFrame\n",
        "print(\"\\nCreating output DataFrame...\")\n",
        "results = []\n",
        "\n",
        "for i in range(n_frames):\n",
        "    result_row = {\n",
        "        'frame': frames[i],\n",
        "        'time_s': times[i],\n",
        "        'normal_x': normals[i, 0] if np.isfinite(normals[i, 0]) else np.nan,\n",
        "        'normal_y': normals[i, 1] if np.isfinite(normals[i, 1]) else np.nan,\n",
        "        'normal_z': normals[i, 2] if np.isfinite(normals[i, 2]) else np.nan,\n",
        "        'angle_change_deg': angle_changes[i] if np.isfinite(angle_changes[i]) else np.nan,\n",
        "        'cumulative_angle_change_deg': cumulative_angle_changes[i] if np.isfinite(cumulative_angle_changes[i]) else np.nan,\n",
        "        'angular_velocity_deg_per_s': angular_velocities[i] if np.isfinite(angular_velocities[i]) else np.nan,\n",
        "        'normal_stability_std': normals_stability_std[i] if np.isfinite(normals_stability_std[i]) else np.nan,\n",
        "        'normal_stability_mean_angle': normals_stability_mean_angle[i] if np.isfinite(normals_stability_mean_angle[i]) else np.nan,\n",
        "        'state_label': state_labels[i],\n",
        "        'filtered_normal_x': filtered_normals[i, 0] if np.isfinite(filtered_normals[i, 0]) else np.nan,\n",
        "        'filtered_normal_y': filtered_normals[i, 1] if np.isfinite(filtered_normals[i, 1]) else np.nan,\n",
        "        'filtered_normal_z': filtered_normals[i, 2] if np.isfinite(filtered_normals[i, 2]) else np.nan,\n",
        "    }\n",
        "    results.append(result_row)\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Per-second block analysis: mean normal per second and angle shift\n",
        "print(\"\\nComputing per-second block angle shifts...\")\n",
        "normals_df = pd.DataFrame({\n",
        "    'time_s': times,\n",
        "    'normal_x': normals[:, 0],\n",
        "    'normal_y': normals[:, 1],\n",
        "    'normal_z': normals[:, 2],\n",
        "})\n",
        "normals_df['second'] = np.floor(normals_df['time_s']).astype(int)\n",
        "\n",
        "sec_rows = []\n",
        "for sec, grp in normals_df.groupby('second'):\n",
        "    vals = grp[['normal_x', 'normal_y', 'normal_z']].values\n",
        "    valid = np.all(np.isfinite(vals), axis=1)\n",
        "    if valid.sum() == 0:\n",
        "        continue\n",
        "    mean_vec = np.mean(vals[valid], axis=0)\n",
        "    if np.all(np.isfinite(mean_vec)) and np.linalg.norm(mean_vec) > 0:\n",
        "        mean_vec = mean_vec / np.linalg.norm(mean_vec)\n",
        "        sec_rows.append({\n",
        "            'second': int(sec),\n",
        "            'time_start_s': float(sec),\n",
        "            'time_end_s': float(sec + 1),\n",
        "            'mean_normal_x': mean_vec[0],\n",
        "            'mean_normal_y': mean_vec[1],\n",
        "            'mean_normal_z': mean_vec[2],\n",
        "            'num_valid_frames': int(valid.sum()),\n",
        "            'num_frames_in_sec': int(len(valid))\n",
        "        })\n",
        "\n",
        "sec_df = pd.DataFrame(sec_rows).sort_values('second').reset_index(drop=True)\n",
        "\n",
        "# Enforce continuity (flip sign if necessary) to avoid 180-deg jumps\n",
        "def angle_deg(n1, n2):\n",
        "    dp = np.clip(np.dot(n1, n2), -1.0, 1.0)\n",
        "    return float(np.degrees(np.arccos(dp)))\n",
        "\n",
        "prev = None\n",
        "for i in range(len(sec_df)):\n",
        "    curr = sec_df.loc[i, ['mean_normal_x','mean_normal_y','mean_normal_z']].values.astype(float)\n",
        "    if prev is not None and np.all(np.isfinite(prev)) and np.all(np.isfinite(curr)):\n",
        "        if np.dot(prev, curr) < 0:\n",
        "            curr = -curr\n",
        "            sec_df.loc[i, ['mean_normal_x','mean_normal_y','mean_normal_z']] = curr\n",
        "    prev = curr\n",
        "\n",
        "# Compute sec-to-sec angle shifts\n",
        "angles = [np.nan]\n",
        "for i in range(1, len(sec_df)):\n",
        "    n1 = sec_df.loc[i-1, ['mean_normal_x','mean_normal_y','mean_normal_z']].values.astype(float)\n",
        "    n2 = sec_df.loc[i,   ['mean_normal_x','mean_normal_y','mean_normal_z']].values.astype(float)\n",
        "    angles.append(angle_deg(n1, n2))\n",
        "sec_df['angle_to_prev_sec_deg'] = angles\n",
        "\n",
        "# Save per-second analysis\n",
        "sec_out = Path(out_root) / 'normal_vector_stability_sec_blocks.csv'\n",
        "sec_out.parent.mkdir(exist_ok=True, parents=True)\n",
        "sec_df.to_csv(sec_out, index=False)\n",
        "print(f\"Per-second block analysis saved to: {sec_out}\")\n",
        "\n",
        "# Summary statistics\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SUMMARY STATISTICS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "valid_mask = np.all(np.isfinite(normals), axis=1)\n",
        "valid_count = np.sum(valid_mask)\n",
        "\n",
        "print(f\"\\nOverall Stability Metrics:\")\n",
        "print(f\"  Mean normal vector: [{stability_metrics['mean_normal'][0]:.6f}, \"\n",
        "      f\"{stability_metrics['mean_normal'][1]:.6f}, {stability_metrics['mean_normal'][2]:.6f}]\")\n",
        "print(f\"  Std dev of components: [{stability_metrics['std_components'][0]:.6f}, \"\n",
        "      f\"{stability_metrics['std_components'][1]:.6f}, {stability_metrics['std_components'][2]:.6f}]\")\n",
        "print(f\"  Mean angular dispersion: {stability_metrics['mean_angular_dispersion']:.4f} degrees\")\n",
        "print(f\"  Coefficient of variation: {stability_metrics['coefficient_of_variation']:.6f}\")\n",
        "\n",
        "print(f\"\\nAngle Change Statistics:\")\n",
        "valid_angles = angle_changes[np.isfinite(angle_changes)]\n",
        "if len(valid_angles) > 0:\n",
        "    print(f\"  Mean angle change: {np.mean(valid_angles):.4f} degrees\")\n",
        "    print(f\"  Std dev angle change: {np.std(valid_angles):.4f} degrees\")\n",
        "    print(f\"  Max angle change: {np.max(valid_angles):.4f} degrees\")\n",
        "    print(f\"  Min angle change: {np.min(valid_angles):.4f} degrees\")\n",
        "\n",
        "print(f\"\\nAngular Velocity Statistics:\")\n",
        "valid_velocities = angular_velocities[np.isfinite(angular_velocities)]\n",
        "if len(valid_velocities) > 0:\n",
        "    print(f\"  Mean angular velocity: {np.mean(valid_velocities):.4f} deg/s\")\n",
        "    print(f\"  Max angular velocity: {np.max(valid_velocities):.4f} deg/s\")\n",
        "\n",
        "# Per-second summary\n",
        "if len(sec_df) > 1:\n",
        "    valid_sec_angles = sec_df['angle_to_prev_sec_deg'].dropna()\n",
        "    if len(valid_sec_angles) > 0:\n",
        "        print(f\"\\nPer-second angle shift (sec-to-sec):\")\n",
        "        print(f\"  Mean: {valid_sec_angles.mean():.4f} deg/sec\")\n",
        "        print(f\"  Median: {valid_sec_angles.median():.4f} deg/sec\")\n",
        "        print(f\"  Max: {valid_sec_angles.max():.4f} deg/sec\")\n",
        "\n",
        "print(f\"\\nState Classification:\")\n",
        "stable_count = np.sum(state_labels == 'stable')\n",
        "changing_count = np.sum(state_labels == 'changing')\n",
        "stable_percent = 100 * stable_count / n_frames if n_frames > 0 else 0\n",
        "changing_percent = 100 * changing_count / n_frames if n_frames > 0 else 0\n",
        "print(f\"  Stable frames: {stable_percent:.2f}% ({stable_count} frames)\")\n",
        "print(f\"  Changing frames: {changing_percent:.2f}% ({changing_count} frames)\")\n",
        "\n",
        "# Time periods with highest/lowest stability\n",
        "valid_stability = normals_stability_std[np.isfinite(normals_stability_std)]\n",
        "if len(valid_stability) > 0:\n",
        "    min_stability_idx = np.argmin(valid_stability)\n",
        "    max_stability_idx = np.argmax(valid_stability)\n",
        "    min_stability_time = times[np.where(np.isfinite(normals_stability_std))[0][min_stability_idx]]\n",
        "    max_stability_time = times[np.where(np.isfinite(normals_stability_std))[0][max_stability_idx]]\n",
        "    \n",
        "    print(f\"\\nStability Periods:\")\n",
        "    print(f\"  Most stable time: {min_stability_time:.3f} s (std: {np.min(valid_stability):.4f} deg)\")\n",
        "    print(f\"  Least stable time: {max_stability_time:.3f} s (std: {np.max(valid_stability):.4f} deg)\")\n",
        "\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Save results\n",
        "output_path = Path(out_root) / 'normal_vector_stability_analysis.csv'\n",
        "output_path.parent.mkdir(exist_ok=True, parents=True)\n",
        "results_df.to_csv(output_path, index=False)\n",
        "print(f\"\\nResults saved to: {output_path}\")\n",
        "print(\"[DONE]\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
