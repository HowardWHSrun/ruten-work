{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f334bb67",
   "metadata": {},
   "source": [
    "## CT Pedestal Computation (Optional Feature)\n",
    "\n",
    "This notebook appends four pedestal landmarks using CT fiducial coordinates that are hardcoded into the QC pipeline so they remain available during reprojection analysis.\n",
    "\n",
    "### Marker Mapping\n",
    "\n",
    "- **Nose tip**: Fiducial `F` aligns with the tracked nose landmark (LPS mm coordinates: `[15.0423, 86.4624, 114.5245]`).\n",
    "- **Pedestal corners**: `F_1` … `F_4` are the pedestal reference points from the same CT scan.\n",
    "\n",
    "### How It Works\n",
    "\n",
    "1. **Hardcoded Offsets**: Each pedestal offset `pedestal_position - nose_position` is precomputed from the embedded CT coordinates.\n",
    "2. **Pedestal Trajectories**: On every frame the offset is added to the tracked nose 3D position to generate `Pedestal_F_1` … `Pedestal_F_4`.\n",
    "3. **Integration**: The extra joints are appended to the 3D array and flow through all reprojection calculations.\n",
    "\n",
    "### Configuration\n",
    "\n",
    "- Set `nose_landmark_name` in the code cell to the tracked nose landmark name (e.g., `\"F\"`).\n",
    "- Toggle `include_ct_pedestals` to `False` if you want to suppress the derived pedestal joints.\n",
    "\n",
    "### Reprojection Error Note\n",
    "\n",
    "The pedestal landmarks are derived from the tracked nose and have no independent 2D tracks. Their reprojection rows will report `n_obs = 0` and `NaN` errors, but the projected locations remain helpful for visual checks inside each camera view.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932a2c05-192f-49ac-8456-1425345107fb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a352620-f1ec-47f4-913e-4d2d20e9939d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step] loading 3D points ...\n",
      "[info] 3D shape: (13107, 20, 3), joints=['J1', 'J2', 'J3', 'J4', 'J5', 'J6', 'J7', 'J8', 'J9', 'J10', 'J11', 'J12', 'J13', 'J14', 'J15', 'J16', 'J17', 'J18', 'J19', 'J20']\n",
      "[step] loading calibration ...\n",
      "[info] cameras in calib: ['cam-topleft.mp4', 'cam-topright.mp4', 'cam-bottomleft.mp4', 'cam-bottomright.mp4']\n",
      "[step] computing reprojection errors ...\n",
      "[step] loading 2D for cam-bottomleft.mp4 from ../data/phase2_sample\\cam-bottomleft.inference.analysis.h5\n",
      "[step] loading 2D for cam-bottomright.mp4 from ../data/phase2_sample\\cam-bottomright.inference.analysis.h5\n",
      "[step] loading 2D for cam-topleft.mp4 from ../data/phase2_sample\\cam-topleft.inference.analysis.h5\n",
      "[step] loading 2D for cam-topright.mp4 from ../data/phase2_sample\\cam-topright.inference.analysis.h5\n",
      "[OK] wrote reprojection CSV: ../results\\reprojection_error_by_cam_and_joint.csv\n",
      "[OK] wrote joint summary CSV: ../results\\reprojection_error_by_joint_overall.csv\n",
      "[DONE]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "PHASE 2 (Reprojection Error QC)\n",
    "--------------------------------\n",
    "For every frame t, every joint j, every camera c:\n",
    "    1. Take 3D point (X,Y,Z) in world / ref camera coordinates.\n",
    "    2. Project into camera c using that camera's 3x4 P matrix.\n",
    "    3. Compare predicted 2D (px) vs actual tracked 2D (px).\n",
    "    4. Euclidean distance in pixels = reprojection error.\n",
    "\n",
    "We report median and p95 reprojection error per (camera, joint),\n",
    "plus an overall summary per joint across cameras.\n",
    "\"\"\"\n",
    "\n",
    "import os, re, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "# ===================== USER PATHS (EDIT THESE) =====================\n",
    "\n",
    "# 3D file (either .h5 with \"tracks\" or .npz with (T,J,3))\n",
    "path_3d    = r\"../data/phase2_sample\\points3d.h5\"\n",
    "\n",
    "# Matching 2D tracking files (the *.inference.analysis.h5 per camera)\n",
    "# IMPORTANT: keys here MUST match the camera names in calibration[\"P\"]\n",
    "cam2d_files = {\n",
    "    \"cam-bottomleft.mp4\":   r\"../data/phase2_sample\\cam-bottomleft.inference.analysis.h5\",\n",
    "    \"cam-bottomright.mp4\":  r\"../data/phase2_sample\\cam-bottomright.inference.analysis.h5\",\n",
    "    \"cam-topleft.mp4\":      r\"../data/phase2_sample\\cam-topleft.inference.analysis.h5\",\n",
    "    \"cam-topright.mp4\":     r\"../data/phase2_sample\\cam-topright.inference.analysis.h5\",\n",
    "}\n",
    "\n",
    "# calibration.json that has P[camera] = 3x4 matrix\n",
    "path_calib = r\"../data/phase2_sample\\calibration.json\"\n",
    "\n",
    "# Output folder\n",
    "out_root   = r\"../results\"\n",
    "os.makedirs(out_root, exist_ok=True)\n",
    "\n",
    "# Hardcoded CT fiducial coordinates in LPS (mm)\n",
    "CT_NOSE_MARKER_NAME = \"F\"\n",
    "CT_NOSE_POSITION_LPS = np.array([\n",
    "    15.04228687286377,\n",
    "    86.46243651882577,\n",
    "    114.52446880550107,\n",
    "], dtype=float)\n",
    "\n",
    "CT_PEDESTAL_POSITIONS_LPS = {\n",
    "    \"F_1\": np.array([0.0031134106684476137, 47.44228744506836, 150.02127075195313], dtype=float),\n",
    "    \"F_2\": np.array([23.697498321533203, 46.341487884521484, 147.47947692871094], dtype=float),\n",
    "    \"F_3\": np.array([11.59162425994873, 39.69370450659213, 155.08550427615032], dtype=float),\n",
    "    \"F_4\": np.array([12.013157142401923, 36.49899038310201, 178.17802063449454], dtype=float),\n",
    "}\n",
    "\n",
    "# ========== CT PEDESTAL CONFIGURATION (OPTIONAL) ==========\n",
    "# The CT fiducial coordinates are embedded below. Set nose_landmark_name to the\n",
    "# tracked nose landmark name (e.g., \"F\" if your 3D skeleton keeps the CT label).\n",
    "# Set include_ct_pedestals=False to skip adding the four pedestal joints.\n",
    "nose_landmark_name = \"F\"    # update to your tracked nose joint name, or set to None to skip\n",
    "include_ct_pedestals = True  # set False to disable pedestal augmentation\n",
    "# =========================================================\n",
    "\n",
    "\n",
    "# ===================== HELPERS =====================\n",
    "\n",
    "def load_3d_tracks_any(path_3dfile):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        pts3d: (T,J,3) float array in the reference/world frame\n",
    "        joint_names: list[str] length J\n",
    "    Assumptions:\n",
    "    - For .h5: dataset \"tracks\" with shape (T,K,J,3) -> take K=0\n",
    "    - For .npz: either one big (T,J,3) or per-joint arrays\n",
    "    - Optionally computes and appends pedestal from CT markers if configured\n",
    "    \"\"\"\n",
    "    ext = os.path.splitext(path_3dfile)[1].lower()\n",
    "\n",
    "    if ext in [\".h5\", \".hdf5\"]:\n",
    "        with h5py.File(path_3dfile, \"r\") as f:\n",
    "            if \"tracks\" not in f:\n",
    "                raise RuntimeError(\"3D H5: expected dataset 'tracks' not found.\")\n",
    "            raw = np.array(f[\"tracks\"])  # expected (T,K,J,3)\n",
    "        if raw.ndim != 4 or raw.shape[-1] != 3:\n",
    "            raise RuntimeError(f\"3D H5 'tracks' has shape {raw.shape}, expected (T,K,J,3).\")\n",
    "\n",
    "        T,K,J,_ = raw.shape\n",
    "        pts3d = raw[:,0,:,:]  # (T,J,3)\n",
    "        joint_names = [f\"J{i+1}\" for i in range(J)]\n",
    "\n",
    "    elif ext == \".npz\":\n",
    "        z = np.load(path_3dfile, allow_pickle=True)\n",
    "        keys = list(z.keys())\n",
    "\n",
    "        # Try big (T,J,3)\n",
    "        cand = [(k, z[k].shape) for k in keys\n",
    "                if hasattr(z[k], \"ndim\")\n",
    "                and z[k].ndim == 3\n",
    "                and z[k].shape[-1] == 3]\n",
    "        if cand:\n",
    "            k_big, shp = sorted(cand, key=lambda kv: kv[1][1], reverse=True)[0]\n",
    "            XYZ = np.array(z[k_big])  # (T,J,3)\n",
    "            T,J,_ = XYZ.shape\n",
    "            if \"nodes\" in z and len(z[\"nodes\"]) == J:\n",
    "                joint_names = [str(s) for s in z[\"nodes\"]]\n",
    "            else:\n",
    "                joint_names = [f\"J{i+1}\" for i in range(J)]\n",
    "            pts3d = XYZ\n",
    "        else:\n",
    "            # Else stitch separate arrays\n",
    "            joint_blocks = []\n",
    "            joint_names  = []\n",
    "            for k in keys:\n",
    "                arr = z[k]\n",
    "                if not hasattr(arr,\"ndim\"):\n",
    "                    continue\n",
    "                if arr.ndim == 2 and arr.shape[1] == 3:\n",
    "                    joint_blocks.append(np.array(arr)) # (T,3)\n",
    "                    joint_names.append(k)\n",
    "                elif arr.ndim == 3 and arr.shape[-1] == 3:\n",
    "                    # e.g. (T,JJ,3)\n",
    "                    T,JJ,_ = arr.shape\n",
    "                    for jsub in range(JJ):\n",
    "                        joint_blocks.append(np.array(arr)[:,jsub,:])\n",
    "                        joint_names.append(f\"{k}{jsub+1}\")\n",
    "            if not joint_blocks:\n",
    "                raise RuntimeError(\"3D NPZ: no suitable 3D arrays found.\")\n",
    "            pts3d = np.stack(joint_blocks, axis=1)  # (T,J,3)\n",
    "    else:\n",
    "        raise RuntimeError(f\"Unsupported 3D file extension: {ext}\")\n",
    "\n",
    "    # ========== ADD PEDESTALS IF CONFIGURED ==========\n",
    "    if include_ct_pedestals and nose_landmark_name:\n",
    "        try:\n",
    "            ct_pedestal_data = compute_ct_pedestal_offsets()\n",
    "            pedestal_offsets = ct_pedestal_data[\"pedestals\"]\n",
    "            print(\n",
    "                f\"[pedestal] Loaded {len(pedestal_offsets)} CT pedestal offsets \"\n",
    "                f\"relative to nose '{ct_pedestal_data['nose_marker']}'\"\n",
    "            )\n",
    "\n",
    "            # Find nose landmark in loaded joints\n",
    "            nose_idx = None\n",
    "            nose_key = nose_landmark_name\n",
    "            if nose_key in joint_names:\n",
    "                nose_idx = joint_names.index(nose_key)\n",
    "            else:\n",
    "                matching_indices = [i for i, n in enumerate(joint_names) if n.lower() == nose_key.lower()]\n",
    "                if matching_indices:\n",
    "                    nose_idx = matching_indices[0]\n",
    "                    nose_key = joint_names[nose_idx]\n",
    "                    print(f\"[pedestal] Matched nose landmark: {nose_key}\")\n",
    "                else:\n",
    "                    print(f\"[pedestal] WARNING: Nose landmark '{nose_landmark_name}' not found in joints.\")\n",
    "                    print(f\"[pedestal] Available joints: {joint_names}\")\n",
    "                    print(f\"[pedestal] Skipping pedestal computation.\")\n",
    "                    return pts3d, joint_names\n",
    "\n",
    "            # Get nose trajectory\n",
    "            nose_traj = pts3d[:, nose_idx, :]  # (T, 3)\n",
    "\n",
    "            # Compute pedestal trajectories\n",
    "            pedestal_trajs = compute_pedestal_trajectories(nose_traj, pedestal_offsets)\n",
    "\n",
    "            # Append pedestals to pts3d and joint names\n",
    "            added_blocks = []\n",
    "            added_joint_names = []\n",
    "            for marker_name, traj in pedestal_trajs.items():\n",
    "                added_blocks.append(traj[:, np.newaxis, :])\n",
    "                added_joint_names.append(f\"Pedestal_{marker_name}\")\n",
    "\n",
    "            if added_blocks:\n",
    "                pts3d = np.concatenate([pts3d] + added_blocks, axis=1)\n",
    "                joint_names.extend(added_joint_names)\n",
    "                print(\n",
    "                    f\"[pedestal] Added pedestal trajectories computed from '{nose_key}': \"\n",
    "                    f\"{', '.join(added_joint_names)}\"\n",
    "                )\n",
    "                print(\"[pedestal] Pedestals will appear in reprojection error calculations\")\n",
    "        except Exception as e:\n",
    "            print(f\"[pedestal] ERROR: Failed to compute pedestals: {e}\")\n",
    "            print(f\"[pedestal] Continuing without pedestals...\")\n",
    "    # ================================================\n",
    "\n",
    "    return pts3d, joint_names\n",
    "\n",
    "\n",
    "def load_2d_from_h5_analysis(path_2dfile):\n",
    "    \"\"\"\n",
    "    YOUR FORMAT (from cam-*.inference.analysis.h5 dump):\n",
    "\n",
    "    tracks shape = (1, 2, 20, 13107)\n",
    "      axis 0: track index (we'll take 0)\n",
    "      axis 1: coord = [x,y]\n",
    "      axis 2: joint index (0..19)\n",
    "      axis 3: frame index (0..T-1)\n",
    "\n",
    "    We want pts2d[frame, joint, xy] = shape (T, J, 2).\n",
    "\n",
    "    Steps:\n",
    "      raw = tracks[0]            -> (2, J, T)\n",
    "      swap axes -> (T, J, 2)\n",
    "    Also returns node_names list for debugging.\n",
    "    \"\"\"\n",
    "    with h5py.File(path_2dfile, \"r\") as f:\n",
    "        if \"tracks\" not in f:\n",
    "            raise RuntimeError(f\"{path_2dfile}: no 'tracks' dataset\")\n",
    "        raw = np.array(f[\"tracks\"])        # (1,2,J,T)\n",
    "        node_names_ds = np.array(f[\"node_names\"])  # (J,)\n",
    "\n",
    "    if raw.ndim != 4:\n",
    "        raise RuntimeError(f\"{path_2dfile}: 'tracks' shape {raw.shape}, expected (1,2,J,T)\")\n",
    "\n",
    "    # squeeze first dim: (2,J,T)\n",
    "    raw2 = raw[0]  # (2, J, T)\n",
    "\n",
    "    # Now we want (T,J,2):\n",
    "    # current axes: (coord=0, joint=1, frame=2)\n",
    "    # move them to (frame, joint, coord) = (2,1,0)\n",
    "    pts2d = np.moveaxis(raw2, [0,1,2], [2,1,0])  # -> (T,J,2)\n",
    "\n",
    "    # decode node names to strings\n",
    "    node_names = []\n",
    "    for n in node_names_ds:\n",
    "        if isinstance(n, (bytes, bytearray)):\n",
    "            node_names.append(n.decode(\"utf-8\"))\n",
    "        else:\n",
    "            node_names.append(str(n))\n",
    "\n",
    "    return pts2d, node_names\n",
    "\n",
    "\n",
    "# ========== CT MARKER OFFSETS (HARDCODED) ==========\n",
    "def compute_ct_pedestal_offsets(ct_dir=None, nose_filename=None, pedestal_filenames=None):\n",
    "    \"\"\"\n",
    "    Provide hardcoded CT offsets for the pedestal fiducials.\n",
    "\n",
    "    Args:\n",
    "        ct_dir: Unused (kept for backward compatibility).\n",
    "        nose_filename: Unused.\n",
    "        pedestal_filenames: Unused.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with:\n",
    "            - \"coordinate_system\": LPS coordinate system string\n",
    "            - \"nose_marker\": Nose marker name\n",
    "            - \"nose_position\": Nose position [x, y, z] in mm\n",
    "            - \"pedestals\": {\n",
    "                marker_name: {\n",
    "                    \"offset\": [dx, dy, dz] in mm,\n",
    "                    \"position\": [x, y, z] in mm,\n",
    "                    \"filename\": synthetic identifier\n",
    "                }\n",
    "              }\n",
    "    \"\"\"\n",
    "    pedestals = {}\n",
    "    for marker_name, pedestal_pos in CT_PEDESTAL_POSITIONS_LPS.items():\n",
    "        offset = pedestal_pos - CT_NOSE_POSITION_LPS\n",
    "        pedestals[marker_name] = {\n",
    "            \"offset\": offset.tolist(),\n",
    "            \"position\": pedestal_pos.tolist(),\n",
    "            \"filename\": f\"hardcoded::{marker_name}\",\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"coordinate_system\": \"LPS\",\n",
    "        \"nose_marker\": CT_NOSE_MARKER_NAME,\n",
    "        \"nose_position\": CT_NOSE_POSITION_LPS.tolist(),\n",
    "        \"pedestals\": pedestals,\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_pedestal_trajectories(nose_trajectory, pedestal_offsets):\n",
    "    \"\"\"\n",
    "    Compute pedestal trajectories from nose landmark trajectory and CT offsets.\n",
    "\n",
    "    For each frame: pedestal_position = nose_position + pedestal_offset\n",
    "\n",
    "    Args:\n",
    "        nose_trajectory: Array of shape (T, 3) where T is number of frames,\n",
    "            each row is [x, y, z] position of nose landmark\n",
    "        pedestal_offsets: Dict mapping marker name -> {\"offset\": [dx, dy, dz], ...}\n",
    "\n",
    "    Returns:\n",
    "        Dict mapping marker name to array of shape (T, 3) with pedestal positions\n",
    "        for each frame\n",
    "    \"\"\"\n",
    "    if nose_trajectory.ndim != 2 or nose_trajectory.shape[1] != 3:\n",
    "        raise ValueError(f\"Expected nose_trajectory shape (T, 3), got {nose_trajectory.shape}\")\n",
    "\n",
    "    trajectories = {}\n",
    "    for marker_name, info in pedestal_offsets.items():\n",
    "        offset = np.array(info[\"offset\"])\n",
    "        if offset.shape != (3,):\n",
    "            raise ValueError(f\"Expected offset shape (3,) for '{marker_name}', got {offset.shape}\")\n",
    "        trajectories[marker_name] = nose_trajectory + offset\n",
    "\n",
    "    return trajectories\n",
    "# ================================================\n",
    "\n",
    "\n",
    "def load_calibration(calib_json_path):\n",
    "    \"\"\"\n",
    "    calibration.json structure includes:\n",
    "      \"P\": { \"cam-name.mp4\": [[3x4], ...], ... }\n",
    "      Optionally: \"pedestal_config\": { \"ct_offset\": [...], \"nose_landmark_name\": \"...\" }\n",
    "\n",
    "    We only need P[camera] to project:\n",
    "        [u,v,w]^T = P @ [X,Y,Z,1]^T\n",
    "        x_pred = u/w\n",
    "        y_pred = v/w\n",
    "    \"\"\"\n",
    "    with open(calib_json_path, \"r\") as f:\n",
    "        calib = json.load(f)\n",
    "\n",
    "    if \"P\" not in calib:\n",
    "        raise RuntimeError(\"calibration.json missing top-level 'P' block\")\n",
    "\n",
    "    cam_models = {}\n",
    "    for cam_name, P_list in calib[\"P\"].items():\n",
    "        P = np.array(P_list, dtype=float)  # (3,4)\n",
    "        if P.shape != (3,4):\n",
    "            raise RuntimeError(f\"P for {cam_name} has shape {P.shape}, expected (3,4)\")\n",
    "        cam_models[cam_name] = {\"P\": P}\n",
    "    return cam_models\n",
    "\n",
    "\n",
    "def reprojection_error_allcams(pts3d, joint_names_3d, cam_models, cam2d_files):\n",
    "    \"\"\"\n",
    "    Compute reprojection error in pixels for each camera/joint.\n",
    "\n",
    "    Inputs:\n",
    "        pts3d           (T,J,3)\n",
    "        joint_names_3d  list[str] len J for the 3D data\n",
    "        cam_models      {camera: {\"P\":(3,4)}}\n",
    "        cam2d_files     {camera: path_to_2d_h5}\n",
    "\n",
    "    Returns:\n",
    "        rows: list of dict rows with:\n",
    "            camera, joint, median_reproj_px, p95_reproj_px, n_obs\n",
    "    \"\"\"\n",
    "    T, J, _ = pts3d.shape\n",
    "    rows = []\n",
    "\n",
    "    for cam_name, h5path in cam2d_files.items():\n",
    "        if cam_name not in cam_models:\n",
    "            print(f\"[warn] camera {cam_name} not in calibration; skipping\")\n",
    "            continue\n",
    "\n",
    "        print(f\"[step] loading 2D for {cam_name} from {h5path}\")\n",
    "        pts2d, node_names_2d = load_2d_from_h5_analysis(h5path)  # (T, J2, 2)\n",
    "        # pts2d[frame, joint, xy], xy=(x,y) in pixels\n",
    "\n",
    "        # Sanity: same frame count?\n",
    "        if pts2d.shape[0] != T:\n",
    "            raise RuntimeError(\n",
    "                f\"Frame mismatch {cam_name}: 3D has {T}, 2D has {pts2d.shape[0]}\"\n",
    "            )\n",
    "\n",
    "        # Handle joint count mismatch (J2 could be different from J)\n",
    "        J2 = pts2d.shape[1]\n",
    "        if J2 < J:\n",
    "            print(f\"[warn] {cam_name}: 2D joints={J2} < 3D joints={J}; trimming 3D.\")\n",
    "            J_use = J2\n",
    "        else:\n",
    "            J_use = J\n",
    "\n",
    "        P = cam_models[cam_name][\"P\"]  # (3,4)\n",
    "\n",
    "        all_err = [[] for _ in range(J_use)]  # collect per-joint pixel errors\n",
    "\n",
    "        # Loop frames\n",
    "        for t in range(T):\n",
    "            xyz = pts3d[t, :J_use, :]          # (J_use,3)\n",
    "            ones = np.ones((J_use,1), float)\n",
    "            xyz1 = np.concatenate([xyz, ones], axis=1)  # (J_use,4)\n",
    "\n",
    "            proj = (P @ xyz1.T).T              # (J_use,3)\n",
    "            u = proj[:,0] / proj[:,2]\n",
    "            v = proj[:,1] / proj[:,2]\n",
    "            pred2d = np.stack([u,v], axis=1)   # (J_use,2)\n",
    "\n",
    "            gt2d = pts2d[t, :J_use, :]         # (J_use,2)\n",
    "\n",
    "            diff = pred2d - gt2d               # (J_use,2)\n",
    "            err = np.sqrt(np.sum(diff**2, axis=1))  # pixel distance\n",
    "            good = np.isfinite(err)\n",
    "\n",
    "            for j_idx in np.where(good)[0]:\n",
    "                # Skip pedestal if it doesn't have 2D tracking data\n",
    "                # (pedestal is computed from nose, so it won't be in 2D tracking)\n",
    "                if j_idx < len(joint_names_3d) and joint_names_3d[j_idx] == \"Pedestal\":\n",
    "                    # For pedestal, we can still compute reprojection but note it's computed, not tracked\n",
    "                    # We'll still record it but it represents the projected position only\n",
    "                    pass  # Include it anyway - it shows where pedestal projects to\n",
    "                all_err[j_idx].append(err[j_idx])\n",
    "\n",
    "        # summarize per joint for this camera\n",
    "        for j_idx in range(J_use):\n",
    "            errs = np.array(all_err[j_idx], float)\n",
    "            errs = errs[np.isfinite(errs)]\n",
    "            if errs.size == 0:\n",
    "                med = np.nan\n",
    "                p95 = np.nan\n",
    "                nobs = 0\n",
    "            else:\n",
    "                med = float(np.median(errs))\n",
    "                p95 = float(np.percentile(errs, 95))\n",
    "                nobs = int(errs.size)\n",
    "\n",
    "            # use 3D joint name if available\n",
    "            if j_idx < len(joint_names_3d):\n",
    "                joint_label = joint_names_3d[j_idx]\n",
    "            else:\n",
    "                joint_label = f\"J{j_idx+1}\"\n",
    "\n",
    "            rows.append(dict(\n",
    "                camera=cam_name,\n",
    "                joint=joint_label,\n",
    "                median_reproj_px=med,\n",
    "                p95_reproj_px=p95,\n",
    "                n_obs=nobs,\n",
    "            ))\n",
    "\n",
    "    return rows\n",
    "\n",
    "\n",
    "# ===================== MAIN =====================\n",
    "\n",
    "print(\"[step] loading 3D points ...\")\n",
    "pts3d, joint_names_3d = load_3d_tracks_any(path_3d)\n",
    "print(f\"[info] 3D shape: {pts3d.shape}, joints={joint_names_3d}\")\n",
    "\n",
    "print(\"[step] loading calibration ...\")\n",
    "cam_models = load_calibration(path_calib)\n",
    "print(f\"[info] cameras in calib:\", list(cam_models.keys()))\n",
    "\n",
    "print(\"[step] computing reprojection errors ...\")\n",
    "rows = reprojection_error_allcams(pts3d, joint_names_3d, cam_models, cam2d_files)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    rows,\n",
    "    columns=[\"camera\",\"joint\",\"median_reproj_px\",\"p95_reproj_px\",\"n_obs\"]\n",
    ")\n",
    "\n",
    "out_csv = os.path.join(out_root, \"reprojection_error_by_cam_and_joint.csv\")\n",
    "df.to_csv(out_csv, index=False)\n",
    "print(\"[OK] wrote reprojection CSV:\", out_csv)\n",
    "\n",
    "# Per-joint (across cameras) summary for quick view:\n",
    "df_joint_summary = (\n",
    "    df.groupby(\"joint\")\n",
    "      .agg(\n",
    "          median_px_overall=(\"median_reproj_px\",\"median\"),\n",
    "          p95_px_overall   =(\"p95_reproj_px\",\"median\"),\n",
    "          total_obs        =(\"n_obs\",\"sum\"),\n",
    "      )\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "out_csv2 = os.path.join(out_root, \"reprojection_error_by_joint_overall.csv\")\n",
    "df_joint_summary.to_csv(out_csv2, index=False)\n",
    "print(\"[OK] wrote joint summary CSV:\", out_csv2)\n",
    "print(\"[DONE]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dc4b4a-0b35-404d-affe-93aa7b247be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bdd57d-9de5-486d-9b2a-2f6d6209426d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sleap-3712)",
   "language": "python",
   "name": "sleap-3712"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
