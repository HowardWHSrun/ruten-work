{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f334bb67",
   "metadata": {},
   "source": [
    "## CT Pedestal Computation (Optional Feature)\n",
    "\n",
    "This notebook supports computing the pedestal location from CT markers and a tracked nose landmark.\n",
    "\n",
    "### How It Works\n",
    "\n",
    "1. **CT Offset**: The offset vector from F_11 (nose reference) to F_9 (pedestal) in CT space\n",
    "2. **Pedestal Computation**: For each frame, the pedestal location is computed as: `pedestal_position = tracked_nose_position + ct_offset`\n",
    "3. **Integration**: The pedestal trajectory is automatically added to the 3D data and included in reprojection error calculations\n",
    "\n",
    "### Configuration\n",
    "\n",
    "**Option 1 (Recommended)**: Directly specify the CT offset vector\n",
    "- Set `ct_offset = [dx, dy, dz]` in mm (this is F_9 - F_11 from your CT markers)\n",
    "- Set `nose_landmark_name` to the name of the tracked landmark (e.g., \"NostrilsTop_Center\")\n",
    "- Example: `ct_offset = [-1.21, -43.64, 52.76]`  # from your CT markers\n",
    "\n",
    "**Option 2**: Load from CT marker files\n",
    "- Set `ct_dir` to the directory containing `F_9.mrk.json` and `F_11.mrk.json`\n",
    "- Set `nose_landmark_name` to the name of the tracked landmark\n",
    "- The offset will be computed automatically from the files\n",
    "\n",
    "If `nose_landmark_name` is `None`, pedestal computation is skipped.\n",
    "\n",
    "### Reprojection Error Note\n",
    "\n",
    "The pedestal is computed from the nose landmark and doesn't have corresponding 2D tracking data. Reprojection error for the pedestal shows where the computed 3D position projects into each camera view, but there's no ground truth 2D position to compare against. This is useful for visualizing where the pedestal would appear in each camera.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932a2c05-192f-49ac-8456-1425345107fb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a352620-f1ec-47f4-913e-4d2d20e9939d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step] loading 3D points ...\n",
      "[info] 3D shape: (13107, 20, 3), joints=['J1', 'J2', 'J3', 'J4', 'J5', 'J6', 'J7', 'J8', 'J9', 'J10', 'J11', 'J12', 'J13', 'J14', 'J15', 'J16', 'J17', 'J18', 'J19', 'J20']\n",
      "[step] loading calibration ...\n",
      "[info] cameras in calib: ['cam-topleft.mp4', 'cam-topright.mp4', 'cam-bottomleft.mp4', 'cam-bottomright.mp4']\n",
      "[step] computing reprojection errors ...\n",
      "[step] loading 2D for cam-bottomleft.mp4 from C:\\Users\\Lenovo\\Desktop\\Phase 2 evaluation reproj\\cam-bottomleft.inference.analysis.h5\n",
      "[step] loading 2D for cam-bottomright.mp4 from C:\\Users\\Lenovo\\Desktop\\Phase 2 evaluation reproj\\cam-bottomright.inference.analysis.h5\n",
      "[step] loading 2D for cam-topleft.mp4 from C:\\Users\\Lenovo\\Desktop\\Phase 2 evaluation reproj\\cam-topleft.inference.analysis.h5\n",
      "[step] loading 2D for cam-topright.mp4 from C:\\Users\\Lenovo\\Desktop\\Phase 2 evaluation reproj\\cam-topright.inference.analysis.h5\n",
      "[OK] wrote reprojection CSV: C:\\Users\\Lenovo\\Desktop\\Phase 2 evaluation reproj\\out_3d_eval\\reprojection_error_by_cam_and_joint.csv\n",
      "[OK] wrote joint summary CSV: C:\\Users\\Lenovo\\Desktop\\Phase 2 evaluation reproj\\out_3d_eval\\reprojection_error_by_joint_overall.csv\n",
      "[DONE]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "PHASE 2 (Reprojection Error QC)\n",
    "--------------------------------\n",
    "For every frame t, every joint j, every camera c:\n",
    "    1. Take 3D point (X,Y,Z) in world / ref camera coordinates.\n",
    "    2. Project into camera c using that camera's 3x4 P matrix.\n",
    "    3. Compare predicted 2D (px) vs actual tracked 2D (px).\n",
    "    4. Euclidean distance in pixels = reprojection error.\n",
    "\n",
    "We report median and p95 reprojection error per (camera, joint),\n",
    "plus an overall summary per joint across cameras.\n",
    "\"\"\"\n",
    "\n",
    "import os, json, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "# ===================== USER PATHS (EDIT THESE) =====================\n",
    "\n",
    "# 3D file (either .h5 with \"tracks\" or .npz with (T,J,3))\n",
    "path_3d    = r\"C:\\Users\\Lenovo\\Desktop\\Phase 2 evaluation reproj\\points3d.h5\"\n",
    "\n",
    "# Matching 2D tracking files (the *.inference.analysis.h5 per camera)\n",
    "# IMPORTANT: keys here MUST match the camera names in calibration[\"P\"]\n",
    "cam2d_files = {\n",
    "    \"cam-bottomleft.mp4\":   r\"C:\\Users\\Lenovo\\Desktop\\Phase 2 evaluation reproj\\cam-bottomleft.inference.analysis.h5\",\n",
    "    \"cam-bottomright.mp4\":  r\"C:\\Users\\Lenovo\\Desktop\\Phase 2 evaluation reproj\\cam-bottomright.inference.analysis.h5\",\n",
    "    \"cam-topleft.mp4\":      r\"C:\\Users\\Lenovo\\Desktop\\Phase 2 evaluation reproj\\cam-topleft.inference.analysis.h5\",\n",
    "    \"cam-topright.mp4\":     r\"C:\\Users\\Lenovo\\Desktop\\Phase 2 evaluation reproj\\cam-topright.inference.analysis.h5\",\n",
    "}\n",
    "\n",
    "# calibration.json that has P[camera] = 3x4 matrix\n",
    "path_calib = r\"C:\\Users\\Lenovo\\Desktop\\Phase 2 evaluation reproj\\calibration.json\"\n",
    "\n",
    "# Output folder\n",
    "out_root   = r\"C:\\Users\\Lenovo\\Desktop\\Phase 2 evaluation reproj\\out_3d_eval\"\n",
    "os.makedirs(out_root, exist_ok=True)\n",
    "\n",
    "# ========== CT PEDESTAL CONFIGURATION (OPTIONAL) ==========\n",
    "# If you want to include pedestal location computed from CT markers:\n",
    "# 1. Set ct_dir to the directory containing F_9.mrk.json and F_11.mrk.json\n",
    "# 2. Set nose_landmark_name to the name of the tracked landmark that corresponds to the nose\n",
    "#    (e.g., \"NostrilsTop_Center\", \"Nose_Tip\", or whatever your tracking system calls it)\n",
    "# 3. The pedestal location will be computed as: pedestal = nose_position + (F_9 - F_11) offset\n",
    "#    This uses the CT-derived offset between F_9 (pedestal) and F_11 (nose reference)\n",
    "# \n",
    "# If you don't want pedestal, leave ct_dir as None or empty string\n",
    "ct_dir = None  # e.g., r\"/path/to/CT\" or None to skip pedestal\n",
    "nose_landmark_name = None  # e.g., \"NostrilsTop_Center\" or None to skip pedestal\n",
    "# =========================================================\n",
    "\n",
    "\n",
    "# ===================== HELPERS =====================\n",
    "\n",
    "def load_3d_tracks_any(path_3dfile):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        pts3d: (T,J,3) float array in the reference/world frame\n",
    "        joint_names: list[str] length J\n",
    "    Assumptions:\n",
    "    - For .h5: dataset \"tracks\" with shape (T,K,J,3) -> take K=0\n",
    "    - For .npz: either one big (T,J,3) or per-joint arrays\n",
    "    - Optionally computes and appends pedestal from CT markers if configured\n",
    "    \"\"\"\n",
    "    ext = os.path.splitext(path_3dfile)[1].lower()\n",
    "\n",
    "    if ext in [\".h5\", \".hdf5\"]:\n",
    "        with h5py.File(path_3dfile, \"r\") as f:\n",
    "            if \"tracks\" not in f:\n",
    "                raise RuntimeError(\"3D H5: expected dataset 'tracks' not found.\")\n",
    "            raw = np.array(f[\"tracks\"])  # expected (T,K,J,3)\n",
    "        if raw.ndim != 4 or raw.shape[-1] != 3:\n",
    "            raise RuntimeError(f\"3D H5 'tracks' has shape {raw.shape}, expected (T,K,J,3).\")\n",
    "\n",
    "        T,K,J,_ = raw.shape\n",
    "        pts3d = raw[:,0,:,:]  # (T,J,3)\n",
    "        joint_names = [f\"J{i+1}\" for i in range(J)]\n",
    "\n",
    "    elif ext == \".npz\":\n",
    "        z = np.load(path_3dfile, allow_pickle=True)\n",
    "        keys = list(z.keys())\n",
    "\n",
    "        # Try big (T,J,3)\n",
    "        cand = [(k, z[k].shape) for k in keys\n",
    "                if hasattr(z[k], \"ndim\")\n",
    "                and z[k].ndim == 3\n",
    "                and z[k].shape[-1] == 3]\n",
    "        if cand:\n",
    "            k_big, shp = sorted(cand, key=lambda kv: kv[1][1], reverse=True)[0]\n",
    "            XYZ = np.array(z[k_big])  # (T,J,3)\n",
    "            T,J,_ = XYZ.shape\n",
    "            if \"nodes\" in z and len(z[\"nodes\"]) == J:\n",
    "                joint_names = [str(s) for s in z[\"nodes\"]]\n",
    "            else:\n",
    "                joint_names = [f\"J{i+1}\" for i in range(J)]\n",
    "            pts3d = XYZ\n",
    "        else:\n",
    "            # Else stitch separate arrays\n",
    "            joint_blocks = []\n",
    "            joint_names  = []\n",
    "            for k in keys:\n",
    "                arr = z[k]\n",
    "                if not hasattr(arr,\"ndim\"):\n",
    "                    continue\n",
    "                if arr.ndim == 2 and arr.shape[1] == 3:\n",
    "                    joint_blocks.append(np.array(arr)) # (T,3)\n",
    "                    joint_names.append(k)\n",
    "                elif arr.ndim == 3 and arr.shape[-1] == 3:\n",
    "                    # e.g. (T,JJ,3)\n",
    "                    T,JJ,_ = arr.shape\n",
    "                    for jsub in range(JJ):\n",
    "                        joint_blocks.append(np.array(arr)[:,jsub,:])\n",
    "                        joint_names.append(f\"{k}{jsub+1}\")\n",
    "            if not joint_blocks:\n",
    "                raise RuntimeError(\"3D NPZ: no suitable 3D arrays found.\")\n",
    "            pts3d = np.stack(joint_blocks, axis=1)  # (T,J,3)\n",
    "    else:\n",
    "        raise RuntimeError(f\"Unsupported 3D file extension: {ext}\")\n",
    "\n",
    "    # ========== ADD PEDESTAL IF CONFIGURED ==========\n",
    "    # If CT directory and nose landmark are specified, compute pedestal trajectory\n",
    "    if ct_dir and nose_landmark_name and os.path.exists(ct_dir):\n",
    "        try:\n",
    "            # Load CT offset\n",
    "            ct_offset_data = compute_ct_offset(ct_dir)\n",
    "            ct_offset = ct_offset_data[\"offset\"]\n",
    "            print(f\"[pedestal] Loaded CT offset: {ct_offset} mm (F_9 - F_11)\")\n",
    "            \n",
    "            # Find nose landmark in loaded joints\n",
    "            nose_idx = None\n",
    "            if nose_landmark_name in joint_names:\n",
    "                nose_idx = joint_names.index(nose_landmark_name)\n",
    "            else:\n",
    "                # Try case-insensitive match\n",
    "                matching_indices = [i for i, n in enumerate(joint_names) if n.lower() == nose_landmark_name.lower()]\n",
    "                if matching_indices:\n",
    "                    nose_idx = matching_indices[0]\n",
    "                    nose_landmark_name = joint_names[nose_idx]\n",
    "                    print(f\"[pedestal] Matched nose landmark: {nose_landmark_name}\")\n",
    "                else:\n",
    "                    print(f\"[pedestal] WARNING: Nose landmark '{nose_landmark_name}' not found in joints.\")\n",
    "                    print(f\"[pedestal] Available joints: {joint_names}\")\n",
    "                    print(f\"[pedestal] Skipping pedestal computation.\")\n",
    "                    return pts3d, joint_names\n",
    "            \n",
    "            # Get nose trajectory\n",
    "            nose_traj = pts3d[:, nose_idx, :]  # (T, 3)\n",
    "            \n",
    "            # Compute pedestal trajectory\n",
    "            pedestal_traj = compute_pedestal_trajectory(nose_traj, ct_offset)  # (T, 3)\n",
    "            \n",
    "            # Append pedestal to pts3d\n",
    "            pedestal_traj_expanded = pedestal_traj[:, np.newaxis, :]  # (T, 1, 3)\n",
    "            pts3d = np.concatenate([pts3d, pedestal_traj_expanded], axis=1)  # (T, J+1, 3)\n",
    "            \n",
    "            # Append pedestal name to joint_names\n",
    "            joint_names.append(\"Pedestal\")\n",
    "            print(f\"[pedestal] Added pedestal trajectory computed from '{nose_landmark_name}'\")\n",
    "            print(f\"[pedestal] Pedestal will appear in reprojection error calculations\")\n",
    "        except Exception as e:\n",
    "            print(f\"[pedestal] ERROR: Failed to compute pedestal: {e}\")\n",
    "            print(f\"[pedestal] Continuing without pedestal...\")\n",
    "    # ================================================\n",
    "\n",
    "    return pts3d, joint_names\n",
    "\n",
    "\n",
    "def load_2d_from_h5_analysis(path_2dfile):\n",
    "    \"\"\"\n",
    "    YOUR FORMAT (from cam-*.inference.analysis.h5 dump):\n",
    "\n",
    "    tracks shape = (1, 2, 20, 13107)\n",
    "      axis 0: track index (we'll take 0)\n",
    "      axis 1: coord = [x,y]\n",
    "      axis 2: joint index (0..19)\n",
    "      axis 3: frame index (0..T-1)\n",
    "\n",
    "    We want pts2d[frame, joint, xy] = shape (T, J, 2).\n",
    "\n",
    "    Steps:\n",
    "      raw = tracks[0]            -> (2, J, T)\n",
    "      swap axes -> (T, J, 2)\n",
    "    Also returns node_names list for debugging.\n",
    "    \"\"\"\n",
    "    with h5py.File(path_2dfile, \"r\") as f:\n",
    "        if \"tracks\" not in f:\n",
    "            raise RuntimeError(f\"{path_2dfile}: no 'tracks' dataset\")\n",
    "        raw = np.array(f[\"tracks\"])        # (1,2,J,T)\n",
    "        node_names_ds = np.array(f[\"node_names\"])  # (J,)\n",
    "\n",
    "    if raw.ndim != 4:\n",
    "        raise RuntimeError(f\"{path_2dfile}: 'tracks' shape {raw.shape}, expected (1,2,J,T)\")\n",
    "\n",
    "    # squeeze first dim: (2,J,T)\n",
    "    raw2 = raw[0]  # (2, J, T)\n",
    "\n",
    "    # Now we want (T,J,2):\n",
    "    # current axes: (coord=0, joint=1, frame=2)\n",
    "    # move them to (frame, joint, coord) = (2,1,0)\n",
    "    pts2d = np.moveaxis(raw2, [0,1,2], [2,1,0])  # -> (T,J,2)\n",
    "\n",
    "    # decode node names to strings\n",
    "    node_names = []\n",
    "    for n in node_names_ds:\n",
    "        if isinstance(n, (bytes, bytearray)):\n",
    "            node_names.append(n.decode(\"utf-8\"))\n",
    "        else:\n",
    "            node_names.append(str(n))\n",
    "\n",
    "    return pts2d, node_names\n",
    "\n",
    "\n",
    "# ========== CT MARKER LOADING FUNCTIONS ==========\n",
    "def load_ct_marker(mrk_json_path):\n",
    "    \"\"\"\n",
    "    Load a CT marker file (.mrk.json) and extract 3D position.\n",
    "    \n",
    "    CT markers are stored in Slicer format with positions in LPS\n",
    "    (Left-Posterior-Superior) coordinate system.\n",
    "    \n",
    "    Args:\n",
    "        mrk_json_path: Path to the .mrk.json file\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with:\n",
    "            - \"name\": marker name (from filename or label)\n",
    "            - \"position\": [x, y, z] in mm\n",
    "            - \"coordinate_system\": \"LPS\"\n",
    "    \"\"\"\n",
    "    if not os.path.exists(mrk_json_path):\n",
    "        raise FileNotFoundError(f\"CT marker file not found: {mrk_json_path}\")\n",
    "    \n",
    "    with open(mrk_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Extract marker name from filename if not in data\n",
    "    marker_name = os.path.splitext(os.path.basename(mrk_json_path))[0]\n",
    "    \n",
    "    # Parse Slicer markups format\n",
    "    if \"markups\" not in data or len(data[\"markups\"]) == 0:\n",
    "        raise ValueError(f\"No markups found in {mrk_json_path}\")\n",
    "    \n",
    "    markup = data[\"markups\"][0]\n",
    "    \n",
    "    if \"controlPoints\" not in markup or len(markup[\"controlPoints\"]) == 0:\n",
    "        raise ValueError(f\"No control points found in {mrk_json_path}\")\n",
    "    \n",
    "    # Get first control point position\n",
    "    control_point = markup[\"controlPoints\"][0]\n",
    "    position = control_point.get(\"position\", None)\n",
    "    \n",
    "    if position is None:\n",
    "        raise ValueError(f\"No position found in control point of {mrk_json_path}\")\n",
    "    \n",
    "    # Extract label if available\n",
    "    label = control_point.get(\"label\", marker_name)\n",
    "    if label and label != marker_name:\n",
    "        marker_name = label.split(\"-\")[0] if \"-\" in label else label\n",
    "    \n",
    "    # Get coordinate system from markup\n",
    "    coord_system = markup.get(\"coordinateSystem\", \"LPS\")\n",
    "    \n",
    "    return {\n",
    "        \"name\": marker_name,\n",
    "        \"position\": list(position),  # [x, y, z] in mm\n",
    "        \"coordinate_system\": coord_system\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_ct_offset(ct_dir, f9_filename=\"F_9.mrk.json\", f11_filename=\"F_11.mrk.json\"):\n",
    "    \"\"\"\n",
    "    Load F_9 and F_11 marker files and compute offset vector.\n",
    "    \n",
    "    The offset is computed as: offset = F_9_position - F_11_position\n",
    "    This offset can be applied to a tracked nose landmark to get pedestal location.\n",
    "    \n",
    "    How it works:\n",
    "    - F_9 is the pedestal location in CT space\n",
    "    - F_11 is the nose reference point in CT space\n",
    "    - The offset (F_9 - F_11) represents the vector from nose to pedestal in CT space\n",
    "    - When applied to the tracked nose position in video space, it gives the pedestal location\n",
    "    \n",
    "    Args:\n",
    "        ct_dir: Directory containing CT marker files\n",
    "        f9_filename: Filename for F_9 marker (pedestal)\n",
    "        f11_filename: Filename for F_11 marker (nose reference)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with:\n",
    "            - \"offset\": [dx, dy, dz] in mm (F_9 - F_11)\n",
    "            - \"coordinate_system\": \"LPS\"\n",
    "            - \"f9_position\": F_9 position\n",
    "            - \"f11_position\": F_11 position\n",
    "    \"\"\"\n",
    "    f9_path = os.path.join(ct_dir, f9_filename)\n",
    "    f11_path = os.path.join(ct_dir, f11_filename)\n",
    "    \n",
    "    f9_data = load_ct_marker(f9_path)\n",
    "    f11_data = load_ct_marker(f11_path)\n",
    "    \n",
    "    f9_pos = np.array(f9_data[\"position\"])\n",
    "    f11_pos = np.array(f11_data[\"position\"])\n",
    "    \n",
    "    offset = f9_pos - f11_pos  # F_9 - F_11\n",
    "    \n",
    "    return {\n",
    "        \"offset\": offset.tolist(),\n",
    "        \"coordinate_system\": f9_data[\"coordinate_system\"],\n",
    "        \"f9_position\": f9_data[\"position\"],\n",
    "        \"f11_position\": f11_data[\"position\"]\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_pedestal_trajectory(nose_trajectory, ct_offset):\n",
    "    \"\"\"\n",
    "    Compute pedestal trajectory from nose landmark trajectory and CT offset.\n",
    "    \n",
    "    For each frame: pedestal_position = nose_position + ct_offset\n",
    "    \n",
    "    Args:\n",
    "        nose_trajectory: Array of shape (T, 3) where T is number of frames,\n",
    "                       each row is [x, y, z] position of nose landmark\n",
    "        ct_offset: Offset vector [dx, dy, dz] from CT markers (F_9 - F_11)\n",
    "        \n",
    "    Returns:\n",
    "        Array of shape (T, 3) with pedestal positions for each frame\n",
    "    \"\"\"\n",
    "    if nose_trajectory.ndim != 2 or nose_trajectory.shape[1] != 3:\n",
    "        raise ValueError(f\"Expected nose_trajectory shape (T, 3), got {nose_trajectory.shape}\")\n",
    "    \n",
    "    offset = np.array(ct_offset)\n",
    "    if offset.shape != (3,):\n",
    "        raise ValueError(f\"Expected ct_offset shape (3,), got {offset.shape}\")\n",
    "    \n",
    "    # For each frame: pedestal = nose + offset\n",
    "    pedestal = nose_trajectory + offset\n",
    "    \n",
    "    return pedestal\n",
    "# ================================================\n",
    "\n",
    "\n",
    "def load_calibration(calib_json_path):\n",
    "    \"\"\"\n",
    "    calibration.json structure includes:\n",
    "      \"P\": { \"cam-name.mp4\": [[3x4], ...], ... }\n",
    "      Optionally: \"pedestal_config\": { \"ct_offset\": [...], \"nose_landmark_name\": \"...\" }\n",
    "\n",
    "    We only need P[camera] to project:\n",
    "        [u,v,w]^T = P @ [X,Y,Z,1]^T\n",
    "        x_pred = u/w\n",
    "        y_pred = v/w\n",
    "    \"\"\"\n",
    "    with open(calib_json_path, \"r\") as f:\n",
    "        calib = json.load(f)\n",
    "\n",
    "    if \"P\" not in calib:\n",
    "        raise RuntimeError(\"calibration.json missing top-level 'P' block\")\n",
    "\n",
    "    cam_models = {}\n",
    "    for cam_name, P_list in calib[\"P\"].items():\n",
    "        P = np.array(P_list, dtype=float)  # (3,4)\n",
    "        if P.shape != (3,4):\n",
    "            raise RuntimeError(f\"P for {cam_name} has shape {P.shape}, expected (3,4)\")\n",
    "        cam_models[cam_name] = {\"P\": P}\n",
    "    return cam_models\n",
    "\n",
    "\n",
    "def reprojection_error_allcams(pts3d, joint_names_3d, cam_models, cam2d_files):\n",
    "    \"\"\"\n",
    "    Compute reprojection error in pixels for each camera/joint.\n",
    "\n",
    "    Inputs:\n",
    "        pts3d           (T,J,3)\n",
    "        joint_names_3d  list[str] len J for the 3D data\n",
    "        cam_models      {camera: {\"P\":(3,4)}}\n",
    "        cam2d_files     {camera: path_to_2d_h5}\n",
    "\n",
    "    Returns:\n",
    "        rows: list of dict rows with:\n",
    "            camera, joint, median_reproj_px, p95_reproj_px, n_obs\n",
    "    \"\"\"\n",
    "    T, J, _ = pts3d.shape\n",
    "    rows = []\n",
    "\n",
    "    for cam_name, h5path in cam2d_files.items():\n",
    "        if cam_name not in cam_models:\n",
    "            print(f\"[warn] camera {cam_name} not in calibration; skipping\")\n",
    "            continue\n",
    "\n",
    "        print(f\"[step] loading 2D for {cam_name} from {h5path}\")\n",
    "        pts2d, node_names_2d = load_2d_from_h5_analysis(h5path)  # (T, J2, 2)\n",
    "        # pts2d[frame, joint, xy], xy=(x,y) in pixels\n",
    "\n",
    "        # Sanity: same frame count?\n",
    "        if pts2d.shape[0] != T:\n",
    "            raise RuntimeError(\n",
    "                f\"Frame mismatch {cam_name}: 3D has {T}, 2D has {pts2d.shape[0]}\"\n",
    "            )\n",
    "\n",
    "        # Handle joint count mismatch (J2 could be different from J)\n",
    "        J2 = pts2d.shape[1]\n",
    "        if J2 < J:\n",
    "            print(f\"[warn] {cam_name}: 2D joints={J2} < 3D joints={J}; trimming 3D.\")\n",
    "            J_use = J2\n",
    "        else:\n",
    "            J_use = J\n",
    "\n",
    "        P = cam_models[cam_name][\"P\"]  # (3,4)\n",
    "\n",
    "        all_err = [[] for _ in range(J_use)]  # collect per-joint pixel errors\n",
    "\n",
    "        # Loop frames\n",
    "        for t in range(T):\n",
    "            xyz = pts3d[t, :J_use, :]          # (J_use,3)\n",
    "            ones = np.ones((J_use,1), float)\n",
    "            xyz1 = np.concatenate([xyz, ones], axis=1)  # (J_use,4)\n",
    "\n",
    "            proj = (P @ xyz1.T).T              # (J_use,3)\n",
    "            u = proj[:,0] / proj[:,2]\n",
    "            v = proj[:,1] / proj[:,2]\n",
    "            pred2d = np.stack([u,v], axis=1)   # (J_use,2)\n",
    "\n",
    "            gt2d = pts2d[t, :J_use, :]         # (J_use,2)\n",
    "\n",
    "            diff = pred2d - gt2d               # (J_use,2)\n",
    "            err = np.sqrt(np.sum(diff**2, axis=1))  # pixel distance\n",
    "            good = np.isfinite(err)\n",
    "\n",
    "            for j_idx in np.where(good)[0]:\n",
    "                # Skip pedestal if it doesn't have 2D tracking data\n",
    "                # (pedestal is computed from nose, so it won't be in 2D tracking)\n",
    "                if j_idx < len(joint_names_3d) and joint_names_3d[j_idx] == \"Pedestal\":\n",
    "                    # For pedestal, we can still compute reprojection but note it's computed, not tracked\n",
    "                    # We'll still record it but it represents the projected position only\n",
    "                    pass  # Include it anyway - it shows where pedestal projects to\n",
    "                all_err[j_idx].append(err[j_idx])\n",
    "\n",
    "        # summarize per joint for this camera\n",
    "        for j_idx in range(J_use):\n",
    "            errs = np.array(all_err[j_idx], float)\n",
    "            errs = errs[np.isfinite(errs)]\n",
    "            if errs.size == 0:\n",
    "                med = np.nan\n",
    "                p95 = np.nan\n",
    "                nobs = 0\n",
    "            else:\n",
    "                med = float(np.median(errs))\n",
    "                p95 = float(np.percentile(errs, 95))\n",
    "                nobs = int(errs.size)\n",
    "\n",
    "            # use 3D joint name if available\n",
    "            if j_idx < len(joint_names_3d):\n",
    "                joint_label = joint_names_3d[j_idx]\n",
    "            else:\n",
    "                joint_label = f\"J{j_idx+1}\"\n",
    "\n",
    "            rows.append(dict(\n",
    "                camera=cam_name,\n",
    "                joint=joint_label,\n",
    "                median_reproj_px=med,\n",
    "                p95_reproj_px=p95,\n",
    "                n_obs=nobs,\n",
    "            ))\n",
    "\n",
    "    return rows\n",
    "\n",
    "\n",
    "# ===================== MAIN =====================\n",
    "\n",
    "print(\"[step] loading 3D points ...\")\n",
    "pts3d, joint_names_3d = load_3d_tracks_any(path_3d)\n",
    "print(f\"[info] 3D shape: {pts3d.shape}, joints={joint_names_3d}\")\n",
    "\n",
    "print(\"[step] loading calibration ...\")\n",
    "cam_models = load_calibration(path_calib)\n",
    "print(f\"[info] cameras in calib:\", list(cam_models.keys()))\n",
    "\n",
    "print(\"[step] computing reprojection errors ...\")\n",
    "rows = reprojection_error_allcams(pts3d, joint_names_3d, cam_models, cam2d_files)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    rows,\n",
    "    columns=[\"camera\",\"joint\",\"median_reproj_px\",\"p95_reproj_px\",\"n_obs\"]\n",
    ")\n",
    "\n",
    "out_csv = os.path.join(out_root, \"reprojection_error_by_cam_and_joint.csv\")\n",
    "df.to_csv(out_csv, index=False)\n",
    "print(\"[OK] wrote reprojection CSV:\", out_csv)\n",
    "\n",
    "# Per-joint (across cameras) summary for quick view:\n",
    "df_joint_summary = (\n",
    "    df.groupby(\"joint\")\n",
    "      .agg(\n",
    "          median_px_overall=(\"median_reproj_px\",\"median\"),\n",
    "          p95_px_overall   =(\"p95_reproj_px\",\"median\"),\n",
    "          total_obs        =(\"n_obs\",\"sum\"),\n",
    "      )\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "out_csv2 = os.path.join(out_root, \"reprojection_error_by_joint_overall.csv\")\n",
    "df_joint_summary.to_csv(out_csv2, index=False)\n",
    "print(\"[OK] wrote joint summary CSV:\", out_csv2)\n",
    "print(\"[DONE]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dc4b4a-0b35-404d-affe-93aa7b247be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bdd57d-9de5-486d-9b2a-2f6d6209426d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sleap-3712)",
   "language": "python",
   "name": "sleap-3712"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
