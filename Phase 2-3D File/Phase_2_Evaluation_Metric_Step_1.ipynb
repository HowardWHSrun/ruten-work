{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac0d84df-414b-4164-8278-e228b063067d",
   "metadata": {},
   "source": [
    "#  3D Tracking Data Quality Control (QC) Report\n",
    "\n",
    "This document explains the purpose, methodology, output, and utility of the provided Python script for 3D trajectory evaluation.\n",
    "\n",
    "---\n",
    "\n",
    "## a. What is this code about?\n",
    "\n",
    "This script performs **Core Quality Control (QC)** for **raw 3D joint tracking data** (like those produced by tools such as SLEAP). It acts as a \"health report\" to assess the quality of the 3D coordinates *before* any post-processing (smoothing, fixing gaps, etc.) is applied.\n",
    "\n",
    "The primary goal is to measure and report on three crucial metrics for every tracked joint:\n",
    "\n",
    "1.  **Coverage (%):** How complete the tracking is.\n",
    "2.  **Jitter (mm/frame):** How jumpy or noisy the tracked position is.\n",
    "3.  **Longest Gap (ms):** The worst continuous loss of tracking data.\n",
    "\n",
    "---\n",
    "\n",
    "## b. How it Works (Methodology)\n",
    "\n",
    "The process is divided into clear, standardized steps:\n",
    "\n",
    "### 1. Data Loading and Setup\n",
    "* **Input Handling:** The `load_3d_any` function automatically detects and loads data from either an **H5 file** (expecting a `tracks` dataset) or an **NPZ file** (handling various structures).\n",
    "* **Time Reference:** The script uses the `fps_override_hz` value (**120.0 Hz** in the provided example) to convert frame counts into time units (milliseconds), which is essential for reporting gap lengths.\n",
    "\n",
    "### 2. Unit Conversion (Standardization)\n",
    "* **Heuristic Check:** It examines the magnitude of the coordinates. If the 99th percentile of the absolute values is less than 2.0, it **assumes the units are meters** and multiplies all coordinates by **1000** to convert them to **millimeters (mm)**.\n",
    "* **Output Consistency:** All final results for Jitter and Longest Gap are reported in `mm` and `ms`, regardless of the input's original units.\n",
    "\n",
    "### 3. Metric Calculation (Per-Joint)\n",
    "\n",
    "| Metric | Calculation Method | Interpretation |\n",
    "| :--- | :--- | :--- |\n",
    "| **Coverage (%)** | Counts frames where all (X, Y, Z) coordinates are **finite** (not $\\text{NaN}$ or missing) and divides by the total number of frames ($T$). | Higher is better (closer to 100%). |\n",
    "| **Jitter (mm/frame)** | Calculates the **Euclidean distance** ($\\sqrt{\\Delta X^2 + \\Delta Y^2 + \\Delta Z^2}$) between a joint's position in frame $t$ and frame $t+1$. It reports the **median** (typical jump) and **95th percentile** ($\\text{p}95$, worst-case jump) of these distances. | Lower is better (closer to $0 \\text{ mm}$). |\n",
    "| **Longest Gap (ms)** | Iterates through the frames to find the **longest continuous sequence of non-valid (missing) data points** (a dropout). This frame count is converted to milliseconds using the FPS ($\\text{Time} = \\frac{\\text{Frames} \\times 1000}{\\text{FPS}}$). | Lower is better (closer to $0 \\text{ ms}$). |\n",
    "\n",
    "### 4. Output Generation\n",
    "* Calculated data is saved into three separate **CSV files** (data tables).\n",
    "* The data is used to generate three descriptive **PNG plots** (bar and scatter plots) for visual inspection.\n",
    "* A concise **`summary.txt`** file is generated with the median values across all joints.\n",
    "\n",
    "---\n",
    "\n",
    "## c. Output it Produces (Output Files)\n",
    "\n",
    "All files are created inside the specified `out_root` folder:\n",
    "\n",
    "| Category | File Name | Format |\n",
    "| :--- | :--- | :--- |\n",
    "| **Data Tables** | `3d_coverage_by_joint.csv` | CSV |\n",
    "| | `3d_jitter_by_joint.csv` | CSV |\n",
    "| | `3d_dropout_by_joint.csv` | CSV |\n",
    "| **Visualizations** | `plot_coverage_by_joint.png` | PNG |\n",
    "| | `plot_jitter_by_joint.png` | PNG |\n",
    "| | `plot_dropout_by_joint.png` | PNG |\n",
    "| **Session Summary** | `summary.txt` | TXT |\n",
    "\n",
    "---\n",
    "\n",
    "## d. What each file means?\n",
    "\n",
    "| File Name | Meaning | Key Metric |\n",
    "| :--- | :--- | :--- |\n",
    "| **`3d_coverage_by_joint.csv`** | Detailed table of how often each joint was successfully tracked (e.g., Joint 1 was tracked 99.8% of the time). | `coverage_pct` |\n",
    "| **`3d_jitter_by_joint.csv`** | Detailed table of the frame-to-frame movement (noise) for each joint. | `median_delta_mm`, `p95_delta_mm` |\n",
    "| **`3d_dropout_by_joint.csv`** | Detailed table of the single worst period of missing data for each joint. | `longest_gap_ms` |\n",
    "| **`plot_coverage_by_joint.png`** | **Bar Chart:** Visual comparison of coverage across all joints (look for high bars). | Coverage (%) |\n",
    "| **`plot_jitter_by_joint.png`** | **Scatter/Line Plot:** Visual comparison of movement noise (look for low dots/lines). | $\\Delta$ per frame (mm) |\n",
    "| **`plot_dropout_by_joint.png`** | **Bar Chart:** Visual comparison of the worst blackout time (look for low bars). | Longest gap (ms) |\n",
    "| **`summary.txt`** | A quick, one-line report with the **median** values for all metrics across the *entire session*. | Overall Session Health |\n",
    "\n",
    "---\n",
    "\n",
    "## e. Console Output Types and What Each Means?\n",
    "\n",
    "The console messages provide feedback on the script's progress:\n",
    "\n",
    "| Output Prefix | Purpose | Interpretation |\n",
    "| :--- | :--- | :--- |\n",
    "| `[info]` | Confirms parameters and loaded data dimensions. | **`T`** = Total frames; **`joints`** = Joint names; **`fps`** = Frame rate used. |\n",
    "| `[units]` | Reports the unit standardization logic. | Confirms whether data was **assumed to be meters** (and multiplied by 1000) or already in **millimeters**. |\n",
    "| `[OK] wrote:` | Confirms successful file saving. | The data tables and plots have been created in the output folder. |\n",
    "| `[SUMMARY]` | The final output line of the script. | The **most important quick-check** of overall data quality (e.g., **Median jitter: 0.85 mm/frame**). |\n",
    "| `[DONE]` | Confirmation of script completion. | Lists the paths to the generated plots. |\n",
    "\n",
    "---\n",
    "\n",
    "## f. How this code helps us\n",
    "\n",
    "This code is essential for **triage and verification** of motion capture data:\n",
    "\n",
    "* **Identifies Flaws Early:** Since the analysis is on **raw** data (no smoothing), it gives an honest assessment of the fundamental quality of the 3D reconstruction, identifying problems caused by poor camera calibration or occlusion.\n",
    "* **Pinpoints Worst Joints:** The per-joint reporting allows researchers to instantly see *which specific joints* are the least reliable (e.g., \"The left ear coverage is only 60%\") and decide whether to ignore that joint or focus manual effort there.\n",
    "* **Quantifies Noise:** The Jitter metric provides a clear, objective number (in $\\text{mm}$) for tracking noise, which is critical for making informed decisions about necessary **data smoothing/filtering** for downstream biomechanical analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d9ae28",
   "metadata": {},
   "source": [
    "## CT Pedestal Computation (Optional Feature)\n",
    "\n",
    "This notebook appends four pedestal landmarks using the latest CT fiducial coordinates baked directly into the code.\n",
    "\n",
    "### Marker Mapping\n",
    "\n",
    "- **Nose tip**: Fiducial `F` corresponds to the tracked nose landmark (LPS mm coordinates: `[15.0423, 86.4624, 114.5245]`).\n",
    "- **Pedestal corners**: `F_1` … `F_4` are the four pedestal reference points drawn from the same CT session.\n",
    "\n",
    "### How It Works\n",
    "\n",
    "1. **Hardcoded Offsets**: Each pedestal uses `offset = pedestal_position - nose_position` computed from the embedded CT coordinates.\n",
    "2. **Pedestal Trajectories**: On every frame we add the offset to the tracked nose 3D position to form `Pedestal_F_1` … `Pedestal_F_4`.\n",
    "3. **Integration**: The new joints flow through all metrics (coverage, jitter, dropout) alongside the tracked markers.\n",
    "\n",
    "### Configuration\n",
    "\n",
    "- Set `nose_landmark_name` in the code cell to the tracked nose landmark name (e.g., `\"F\"`).\n",
    "- Toggle `include_ct_pedestals` to `False` if you need to disable the extra joints.\n",
    "\n",
    "### Coordinate System Note\n",
    "\n",
    "The CT fiducials are expressed in LPS (Left-Posterior-Superior) coordinates. No additional transforms are applied before the offsets are combined with the tracked nose landmark; add any required transforms separately if your 3D data uses a different basis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac9dae2-09a1-4b00-8377-45cd20882a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6905c54-113f-44d4-a118-f97c95a5d5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] T=13357, joints=['J1', 'J2', 'J3', 'J4', 'J5', 'J6', 'J7', 'J8', 'J9', 'J10', 'J11', 'J12', 'J13', 'J14', 'J15', 'J16', 'J17', 'J18', 'J19', 'J20'], fps=120.0\n",
      "[units] treating as millimeters → multiplying by 1.0 to report in mm\n",
      "[OK] wrote: C:\\Users\\Lenovo\\Desktop\\Sleap Final Predictions\\out_3d_eval\\3d_coverage_by_joint.csv\n",
      "[OK] wrote: C:\\Users\\Lenovo\\Desktop\\Sleap Final Predictions\\out_3d_eval\\3d_jitter_by_joint.csv\n",
      "[OK] wrote: C:\\Users\\Lenovo\\Desktop\\Sleap Final Predictions\\out_3d_eval\\3d_dropout_by_joint.csv\n",
      "[SUMMARY] Coverage median: 100.0% | Median jitter: 0.10 mm/frame | Median worst-gap: 0.0 ms\n",
      "[DONE] Plots:\n",
      "  C:\\Users\\Lenovo\\Desktop\\Sleap Final Predictions\\out_3d_eval\\plot_coverage_by_joint.png\n",
      "  C:\\Users\\Lenovo\\Desktop\\Sleap Final Predictions\\out_3d_eval\\plot_jitter_by_joint.png\n",
      "  C:\\Users\\Lenovo\\Desktop\\Sleap Final Predictions\\out_3d_eval\\plot_dropout_by_joint.png\n"
     ]
    }
   ],
   "source": [
    "# === PHASE 2 • 3D EVALUATION ===============================================\n",
    "# Core QC for final 3D tracks (no smoothing, no fixing, just truth):\n",
    "#   1. Coverage (%)            - how often each joint is valid\n",
    "#   2. Jitter (mm/frame)       - how jumpy each joint is frame-to-frame\n",
    "#   3. Longest gap (ms)        - worst continuous blackout for each joint\n",
    "#\n",
    "# INPUT:\n",
    "#   data_path:\n",
    "#       EITHER an NPZ containing 3D joint trajectories\n",
    "#       OR an H5 containing a 'tracks' dataset shaped (T, K, J, 3)\n",
    "#\n",
    "#   fps_override_hz:\n",
    "#       If not None, we force that FPS (e.g. 120.0).\n",
    "#       If None, we try to read \"FPS\" from the file. If still None, we can't\n",
    "#       convert gap length to ms (we'll still report frames).\n",
    "#\n",
    "# OUTPUT FOLDER:\n",
    "#   out_root/\n",
    "#       3d_coverage_by_joint.csv\n",
    "#       3d_jitter_by_joint.csv\n",
    "#       3d_dropout_by_joint.csv\n",
    "#\n",
    "#       plot_coverage_by_joint.png\n",
    "#       plot_jitter_by_joint.png\n",
    "#       plot_dropout_by_joint.png\n",
    "#\n",
    "#       summary.txt\n",
    "#\n",
    "# All numbers are direct from data. No smoothing, no filtering,\n",
    "# no threshold cutoffs. This is an honest health report of the raw 3D tracks.\n",
    "# ============================================================================\n",
    "\n",
    "data_path        = r\"C:\\Users\\Lenovo\\Desktop\\Sleap Final Predictions\\points3d.h5\"\n",
    "out_root         = r\"C:\\Users\\Lenovo\\Desktop\\Sleap Final Predictions\\out_3d_eval\"\n",
    "fps_override_hz  = 120.0   # <-- set 120.0 if you know capture rate; else None\n",
    "\n",
    "# ========== CT PEDESTAL CONFIGURATION (OPTIONAL) ==========\n",
    "# The CT fiducial coordinates are embedded below. Set nose_landmark_name to the\n",
    "# tracked nose landmark name (e.g., \"F\" if your 3D skeleton keeps the CT label).\n",
    "# Set include_ct_pedestals=False to skip adding the four pedestal joints.\n",
    "nose_landmark_name = \"F\"   # update to your tracked nose joint name, or set to None to skip\n",
    "include_ct_pedestals = True  # set False to disable pedestal augmentation\n",
    "# =========================================================\n",
    "\n",
    "import os, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "# Hardcoded CT fiducial coordinates in LPS (mm)\n",
    "CT_NOSE_MARKER_NAME = \"F\"\n",
    "CT_NOSE_POSITION_LPS = np.array([\n",
    "    15.04228687286377,\n",
    "    86.46243651882577,\n",
    "    114.52446880550107,\n",
    "], dtype=float)\n",
    "\n",
    "CT_PEDESTAL_POSITIONS_LPS = {\n",
    "    \"F_1\": np.array([0.0031134106684476137, 47.44228744506836, 150.02127075195313], dtype=float),\n",
    "    \"F_2\": np.array([23.697498321533203, 46.341487884521484, 147.47947692871094], dtype=float),\n",
    "    \"F_3\": np.array([11.59162425994873, 39.69370450659213, 155.08550427615032], dtype=float),\n",
    "    \"F_4\": np.array([12.013157142401923, 36.49899038310201, 178.17802063449454], dtype=float),\n",
    "}\n",
    "\n",
    "os.makedirs(out_root, exist_ok=True)\n",
    "\n",
    "\n",
    "def _load_from_npz(path):\n",
    "    \"\"\"\n",
    "    NPZ loader.\n",
    "    Returns:\n",
    "        joints_dict: {name: (T,3)}\n",
    "        fps: float or None\n",
    "    \"\"\"\n",
    "    z = np.load(path, allow_pickle=True)\n",
    "    keys = list(z.keys())\n",
    "    print(\"[info:npz] keys:\", keys)\n",
    "\n",
    "    joints = {}\n",
    "    had_nodes_names = False\n",
    "\n",
    "    # ---- Case A: one big (T,J,3) block ----\n",
    "    cand = [(k, z[k].shape) for k in keys\n",
    "            if hasattr(z[k], \"ndim\")\n",
    "            and z[k].ndim == 3\n",
    "            and z[k].shape[-1] == 3]\n",
    "    if cand:\n",
    "        # choose array with largest J\n",
    "        k_big, shp = sorted(cand, key=lambda kv: kv[1][1], reverse=True)[0]\n",
    "        XYZ = z[k_big]          # (T,J,3)\n",
    "        T, J, _ = XYZ.shape\n",
    "\n",
    "        # joint names if provided\n",
    "        if \"nodes\" in z and len(z[\"nodes\"]) == J:\n",
    "            names = [str(s) for s in z[\"nodes\"]]\n",
    "            had_nodes_names = True\n",
    "        else:\n",
    "            names = [f\"J{j+1}\" for j in range(J)]\n",
    "\n",
    "        for j, name in enumerate(names):\n",
    "            joints[name] = XYZ[:, j, :]  # (T,3)\n",
    "\n",
    "        fps = float(z[\"FPS\"]) if \"FPS\" in z else None\n",
    "\n",
    "        # if names are just \"J1\", \"J2\"... and we ALSO see semantic keys like\n",
    "        # 'U3','L3','H3', try to remap (best effort)\n",
    "        def try_make_human_names(joints_dict, raw_keys, had_nodes):\n",
    "            if had_nodes:\n",
    "                return joints_dict\n",
    "            all_names = list(joints_dict.keys())\n",
    "            all_generic = all(re.match(r\"^J\\d+$\", n) for n in all_names)\n",
    "            if not all_generic:\n",
    "                return joints_dict  # already meaningful\n",
    "            # guess semantic order from raw_keys (e.g. [\"U3\",\"L3\",\"H3\"])\n",
    "            sem = []\n",
    "            for kk in raw_keys:\n",
    "                if kk.upper() == \"FPS\": \n",
    "                    continue\n",
    "                sem.append(kk)\n",
    "            # dedupe while preserving order\n",
    "            seen_tmp = set()\n",
    "            sem_clean = []\n",
    "            for s in sem:\n",
    "                if s not in seen_tmp:\n",
    "                    sem_clean.append(s)\n",
    "                    seen_tmp.add(s)\n",
    "            js_sorted = sorted(\n",
    "                [n for n in all_names if re.match(r\"^J\\d+$\", n)],\n",
    "                key=lambda x: int(x[1:])\n",
    "            )\n",
    "            if len(js_sorted) == len(sem_clean):\n",
    "                new_joints = {}\n",
    "                mapping = {js_sorted[i]: sem_clean[i] for i in range(len(js_sorted))}\n",
    "                for old_name, xyz in joints_dict.items():\n",
    "                    new_name = mapping.get(old_name, old_name)\n",
    "                    new_joints[new_name] = xyz\n",
    "                return new_joints\n",
    "            return joints_dict\n",
    "\n",
    "        joints = try_make_human_names(joints, keys, had_nodes_names)\n",
    "        return joints, fps\n",
    "\n",
    "    # ---- Case B: separate arrays per joint name ----\n",
    "    for k in keys:\n",
    "        arr = z[k]\n",
    "        if not hasattr(arr, \"ndim\"):\n",
    "            continue\n",
    "        if arr.ndim == 2 and arr.shape[1] == 3:\n",
    "            joints[k] = arr  # (T,3)\n",
    "        elif arr.ndim == 3 and arr.shape[-1] == 3:\n",
    "            # e.g. H3 is (T,3,3) -> split into H31,H32,H33\n",
    "            T, JJ, _ = arr.shape\n",
    "            base = re.sub(r\"\\W+$\", \"\", k)\n",
    "            for j in range(JJ):\n",
    "                joints[f\"{base}{j+1}\"] = arr[:, j, :]\n",
    "    fps = float(z[\"FPS\"]) if \"FPS\" in z else None\n",
    "\n",
    "    if not joints:\n",
    "        raise RuntimeError(\"NPZ: couldn't find any (T,3) or (T,J,3) data\")\n",
    "    return joints, fps\n",
    "\n",
    "\n",
    "def _load_from_h5(path):\n",
    "    \"\"\"\n",
    "    H5 loader for files like points3d.h5 with dataset 'tracks' of shape (T,K,J,3).\n",
    "    Returns:\n",
    "        joints_dict: {name: (T,3)}\n",
    "        fps: None (H5 doesn't have FPS unless you add later)\n",
    "    \"\"\"\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        if \"tracks\" not in f:\n",
    "            raise RuntimeError(\"H5: expected dataset 'tracks' not found.\")\n",
    "        arr = np.array(f[\"tracks\"])  # shape (T,K,J,3)\n",
    "    if arr.ndim != 4 or arr.shape[-1] != 3:\n",
    "        raise RuntimeError(f\"H5: unexpected tracks shape {arr.shape}, expected (T,K,J,3)\")\n",
    "    T, K, J, _ = arr.shape\n",
    "\n",
    "    # pick first track (K=1 in your dump)\n",
    "    xyz = arr[:, 0, :, :]  # (T,J,3)\n",
    "\n",
    "    joints = {}\n",
    "    for j in range(J):\n",
    "        joints[f\"J{j+1}\"] = xyz[:, j, :]  # (T,3)\n",
    "\n",
    "    fps = None  # h5 didn't expose FPS\n",
    "    return joints, fps\n",
    "\n",
    "\n",
    "# ========== CT MARKER OFFSETS (HARDCODED) ==========\n",
    "def compute_ct_pedestal_offsets(ct_dir=None, nose_filename=None, pedestal_filenames=None):\n",
    "    \"\"\"\n",
    "    Provide hardcoded CT offsets for the pedestal fiducials.\n",
    "\n",
    "    Args:\n",
    "        ct_dir: Unused (kept for backward compatibility).\n",
    "        nose_filename: Unused.\n",
    "        pedestal_filenames: Unused.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with:\n",
    "            - \"coordinate_system\": LPS coordinate system string\n",
    "            - \"nose_marker\": Nose marker name\n",
    "            - \"nose_position\": Nose position [x, y, z] in mm\n",
    "            - \"pedestals\": {\n",
    "                marker_name: {\n",
    "                    \"offset\": [dx, dy, dz] in mm,\n",
    "                    \"position\": [x, y, z] in mm,\n",
    "                    \"filename\": synthetic identifier\n",
    "                }\n",
    "              }\n",
    "    \"\"\"\n",
    "    pedestals = {}\n",
    "    for marker_name, pedestal_pos in CT_PEDESTAL_POSITIONS_LPS.items():\n",
    "        offset = pedestal_pos - CT_NOSE_POSITION_LPS\n",
    "        pedestals[marker_name] = {\n",
    "            \"offset\": offset.tolist(),\n",
    "            \"position\": pedestal_pos.tolist(),\n",
    "            \"filename\": f\"hardcoded::{marker_name}\",\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"coordinate_system\": \"LPS\",\n",
    "        \"nose_marker\": CT_NOSE_MARKER_NAME,\n",
    "        \"nose_position\": CT_NOSE_POSITION_LPS.tolist(),\n",
    "        \"pedestals\": pedestals,\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_pedestal_trajectories(nose_trajectory, pedestal_offsets):\n",
    "    \"\"\"\n",
    "    Compute pedestal trajectories from nose landmark trajectory and CT offsets.\n",
    "\n",
    "    For each frame: pedestal_position = nose_position + pedestal_offset\n",
    "\n",
    "    Args:\n",
    "        nose_trajectory: Array of shape (T, 3) where T is number of frames,\n",
    "            each row is [x, y, z] position of nose landmark\n",
    "        pedestal_offsets: Dict mapping marker name -> {\"offset\": [dx, dy, dz], ...}\n",
    "\n",
    "    Returns:\n",
    "        Dict mapping marker name to array of shape (T, 3) with pedestal positions\n",
    "        for each frame\n",
    "    \"\"\"\n",
    "    if nose_trajectory.ndim != 2 or nose_trajectory.shape[1] != 3:\n",
    "        raise ValueError(f\"Expected nose_trajectory shape (T, 3), got {nose_trajectory.shape}\")\n",
    "\n",
    "    trajectories = {}\n",
    "    for marker_name, info in pedestal_offsets.items():\n",
    "        offset = np.array(info[\"offset\"])\n",
    "        if offset.shape != (3,):\n",
    "            raise ValueError(f\"Expected offset shape (3,) for '{marker_name}', got {offset.shape}\")\n",
    "        trajectories[marker_name] = nose_trajectory + offset\n",
    "\n",
    "    return trajectories\n",
    "# ================================================\n",
    "\n",
    "\n",
    "def load_3d_any(path):\n",
    "    \"\"\"\n",
    "    Unified loader:\n",
    "      - dispatch to NPZ loader or H5 loader\n",
    "      - apply fps override if provided\n",
    "      - optionally compute and append pedestal from CT markers\n",
    "    \"\"\"\n",
    "    ext = os.path.splitext(path)[1].lower()\n",
    "    if ext == \".npz\":\n",
    "        joints, fps = _load_from_npz(path)\n",
    "    elif ext == \".h5\" or ext == \".hdf5\":\n",
    "        joints, fps = _load_from_h5(path)\n",
    "    else:\n",
    "        raise RuntimeError(f\"Unsupported file extension: {ext}\")\n",
    "\n",
    "    # manual FPS override (e.g. force 120 Hz instead of whatever/None)\n",
    "    if fps_override_hz is not None:\n",
    "        fps = float(fps_override_hz)\n",
    "\n",
    "    # ========== ADD PEDESTALS IF CONFIGURED ==========\n",
    "    if include_ct_pedestals and nose_landmark_name:\n",
    "        try:\n",
    "            ct_pedestal_data = compute_ct_pedestal_offsets()\n",
    "            pedestal_offsets = ct_pedestal_data[\"pedestals\"]\n",
    "            print(\n",
    "                f\"[pedestal] Loaded {len(pedestal_offsets)} CT pedestal offsets \"\n",
    "                f\"relative to nose '{ct_pedestal_data['nose_marker']}'\"\n",
    "            )\n",
    "\n",
    "            # Find nose landmark in loaded joints\n",
    "            nose_key = nose_landmark_name\n",
    "            if nose_key not in joints:\n",
    "                matching_names = [n for n in joints.keys() if n.lower() == nose_key.lower()]\n",
    "                if matching_names:\n",
    "                    nose_key = matching_names[0]\n",
    "                    print(f\"[pedestal] Matched nose landmark: {nose_key}\")\n",
    "                else:\n",
    "                    print(f\"[pedestal] WARNING: Nose landmark '{nose_landmark_name}' not found in joints.\")\n",
    "                    print(f\"[pedestal] Available joints: {list(joints.keys())}\")\n",
    "                    print(f\"[pedestal] Skipping pedestal computation.\")\n",
    "                    return joints, fps\n",
    "\n",
    "            # Get nose trajectory\n",
    "            nose_traj = joints[nose_key]  # (T, 3)\n",
    "\n",
    "            # Compute pedestal trajectories\n",
    "            pedestal_trajs = compute_pedestal_trajectories(nose_traj, pedestal_offsets)\n",
    "\n",
    "            # Add pedestals to joints dictionary\n",
    "            added_joint_names = []\n",
    "            for marker_name, traj in pedestal_trajs.items():\n",
    "                joint_name = f\"Pedestal_{marker_name}\"\n",
    "                joints[joint_name] = traj\n",
    "                added_joint_names.append(joint_name)\n",
    "\n",
    "            joined = \", \".join(added_joint_names)\n",
    "            print(f\"[pedestal] Added pedestal trajectories computed from '{nose_key}': {joined}\")\n",
    "            print(\"[pedestal] Pedestals will appear in all metrics and outputs\")\n",
    "        except Exception as e:\n",
    "            print(f\"[pedestal] ERROR: Failed to compute pedestals: {e}\")\n",
    "            print(f\"[pedestal] Continuing without pedestals...\")\n",
    "    # ================================================\n",
    "\n",
    "    return joints, fps\n",
    "\n",
    "\n",
    "# ---------- load data ---------- #\n",
    "joints, fps = load_3d_any(data_path)\n",
    "\n",
    "names = list(joints.keys())\n",
    "T = len(next(iter(joints.values())))\n",
    "print(f\"[info] T={T}, joints={names}, fps={fps or 'unknown'}\")\n",
    "\n",
    "# ---------------- Units: convert everything to mm for reporting ------------ #\n",
    "# Heuristic:\n",
    "#   If coordinate magnitudes are <~2 units, assume meters -> convert to mm.\n",
    "#   Else assume already mm.\n",
    "all_vals = np.concatenate([joints[n].reshape(-1,3) for n in names], axis=0)\n",
    "finite_mask = np.isfinite(all_vals).all(axis=1)\n",
    "rng = np.nanpercentile(np.abs(all_vals[finite_mask]), 99)\n",
    "assume_meters = rng < 2.0\n",
    "scale_to_mm = 1000.0 if assume_meters else 1.0\n",
    "print(f\"[units] treating as {'meters' if assume_meters else 'millimeters'} \"\n",
    "      f\"→ multiplying by {scale_to_mm} to report in mm\")\n",
    "\n",
    "def to_mm(X):\n",
    "    return X * scale_to_mm\n",
    "\n",
    "# ---------------- Metric 1: Coverage --------------------------------------- #\n",
    "cov_rows = []\n",
    "for n in names:\n",
    "    xyz = joints[n]  # (T,3)\n",
    "    valid = np.isfinite(xyz).all(axis=1)  # True if that frame has all coords finite\n",
    "    cov_pct = 100.0 * valid.mean()\n",
    "    cov_rows.append(dict(\n",
    "        joint=n,\n",
    "        coverage_pct=cov_pct,\n",
    "        n_valid=int(valid.sum()),\n",
    "        n_total=T,\n",
    "    ))\n",
    "df_cov = pd.DataFrame(cov_rows).sort_values(\"joint\")\n",
    "\n",
    "# ---------------- Metric 2: Jitter ----------------------------------------- #\n",
    "def per_frame_delta_mm(xyz):\n",
    "    diffs = np.diff(to_mm(xyz), axis=0)   # (T-1,3) in mm\n",
    "    d = np.linalg.norm(diffs, axis=1)    # Euclidean step distance in mm\n",
    "    d = d[np.isfinite(d)]\n",
    "    return d\n",
    "\n",
    "jit_rows = []\n",
    "for n in names:\n",
    "    d = per_frame_delta_mm(joints[n])\n",
    "    if d.size == 0:\n",
    "        med = np.nan\n",
    "        p95 = np.nan\n",
    "    else:\n",
    "        med = float(np.median(d))\n",
    "        p95 = float(np.percentile(d, 95))\n",
    "    jit_rows.append(dict(\n",
    "        joint=n,\n",
    "        median_delta_mm=med,\n",
    "        p95_delta_mm=p95,\n",
    "        n_pairs=int(d.size),\n",
    "    ))\n",
    "df_jit = pd.DataFrame(jit_rows).sort_values(\"joint\")\n",
    "\n",
    "# ---------------- Metric 3: Longest dropout gap ---------------------------- #\n",
    "def longest_gap_info(xyz, fps_val):\n",
    "    valid = np.isfinite(xyz).all(axis=1)  # shape (T,)\n",
    "    longest_len_frames = 0\n",
    "    cur_len = 0\n",
    "    for v in valid:\n",
    "        if not v:\n",
    "            cur_len += 1\n",
    "        else:\n",
    "            if cur_len > longest_len_frames:\n",
    "                longest_len_frames = cur_len\n",
    "            cur_len = 0\n",
    "    if cur_len > longest_len_frames:\n",
    "        longest_len_frames = cur_len\n",
    "\n",
    "    if fps_val is not None and fps_val > 0:\n",
    "        ms = 1000.0 * (longest_len_frames / fps_val)\n",
    "    else:\n",
    "        ms = np.nan\n",
    "    return longest_len_frames, ms\n",
    "\n",
    "drop_rows = []\n",
    "for n in names:\n",
    "    longest_frames, longest_ms = longest_gap_info(joints[n], fps)\n",
    "    cov_pct = float(df_cov[df_cov[\"joint\"] == n][\"coverage_pct\"].iloc[0])\n",
    "    drop_rows.append(dict(\n",
    "        joint=n,\n",
    "        coverage_pct=cov_pct,\n",
    "        longest_gap_frames=longest_frames,\n",
    "        longest_gap_ms=longest_ms,\n",
    "    ))\n",
    "df_drop = pd.DataFrame(drop_rows).sort_values(\"joint\")\n",
    "\n",
    "# ---------------- Save CSVs ------------------------------------------------ #\n",
    "p_cov  = os.path.join(out_root, \"3d_coverage_by_joint.csv\")\n",
    "p_jit  = os.path.join(out_root, \"3d_jitter_by_joint.csv\")\n",
    "p_drop = os.path.join(out_root, \"3d_dropout_by_joint.csv\")\n",
    "\n",
    "df_cov.to_csv(p_cov,  index=False)\n",
    "df_jit.to_csv(p_jit,  index=False)\n",
    "df_drop.to_csv(p_drop, index=False)\n",
    "\n",
    "print(\"[OK] wrote:\", p_cov)\n",
    "print(\"[OK] wrote:\", p_jit)\n",
    "print(\"[OK] wrote:\", p_drop)\n",
    "\n",
    "# ---------------- Plots ---------------------------------------------------- #\n",
    "def pretty_names(xs):\n",
    "    return [re.sub(r\"\\.npz$\",\"\", re.sub(r\"[_\\s]+\",\" \", x)).strip() for x in xs]\n",
    "\n",
    "# A) Coverage\n",
    "plt.figure(figsize=(8,3.0))\n",
    "order_cov = df_cov.sort_values(\"coverage_pct\", ascending=False)\n",
    "plt.bar(pretty_names(order_cov[\"joint\"]), order_cov[\"coverage_pct\"])\n",
    "plt.ylim(0,100)\n",
    "plt.ylabel(\"Coverage (%)\")\n",
    "plt.title(\"3D Coverage by Joint\")\n",
    "plt.xticks(rotation=30, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(out_root, \"plot_coverage_by_joint.png\"), dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# B) Jitter\n",
    "plt.figure(figsize=(8,3.0))\n",
    "order_jit = df_jit.sort_values(\"median_delta_mm\", ascending=True)\n",
    "xpos = np.arange(len(order_jit))\n",
    "plt.scatter(xpos, order_jit[\"median_delta_mm\"])\n",
    "for i, (m, p) in enumerate(zip(order_jit[\"median_delta_mm\"],\n",
    "                                order_jit[\"p95_delta_mm\"])):\n",
    "    if np.isfinite(m) and np.isfinite(p):\n",
    "        plt.plot([i,i], [m, p], linewidth=2)\n",
    "plt.xticks(xpos, pretty_names(order_jit[\"joint\"]), rotation=30, ha=\"right\")\n",
    "plt.ylabel(\"Δ per frame (mm)\")\n",
    "plt.title(\"3D Jitter by Joint (median • p95)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(out_root, \"plot_jitter_by_joint.png\"), dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# C) Longest dropout\n",
    "plt.figure(figsize=(8,3.0))\n",
    "order_drop = df_drop.sort_values(\"longest_gap_ms\", ascending=False)\n",
    "plt.bar(pretty_names(order_drop[\"joint\"]), order_drop[\"longest_gap_ms\"])\n",
    "plt.ylabel(\"Longest gap (ms)\")\n",
    "plt.title(\"Worst Continuous Dropout Per Joint (lower is better)\")\n",
    "plt.xticks(rotation=30, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(out_root, \"plot_dropout_by_joint.png\"), dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# ---------------- One-line session summary --------------------------------- #\n",
    "median_cov_pct     = float(np.nanmedian(df_cov[\"coverage_pct\"]))\n",
    "median_jitter_mm   = float(np.nanmedian(df_jit[\"median_delta_mm\"]))\n",
    "median_worst_gapms = float(np.nanmedian(df_drop[\"longest_gap_ms\"])) if fps else np.nan\n",
    "\n",
    "summary = (\n",
    "    f\"Coverage median: {median_cov_pct:.1f}% | \"\n",
    "    f\"Median jitter: {median_jitter_mm:.2f} mm/frame | \"\n",
    "    f\"Median worst-gap: {median_worst_gapms:.1f} ms\"\n",
    ")\n",
    "\n",
    "with open(os.path.join(out_root, \"summary.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(summary + \"\\n\")\n",
    "\n",
    "print(\"[SUMMARY]\", summary)\n",
    "print(\"[DONE] Plots:\",\n",
    "      os.path.join(out_root,\"plot_coverage_by_joint.png\"),\n",
    "      os.path.join(out_root,\"plot_jitter_by_joint.png\"),\n",
    "      os.path.join(out_root,\"plot_dropout_by_joint.png\"),\n",
    "      sep=\"\\n  \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3440a5d9-4543-4987-af35-f294b3c24b99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1814a4e9-58dd-4091-b395-d65a6a5dac8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982ee9fb-8ad8-422b-acc1-b5f925019eec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787926c1-9663-49c5-b655-a11b4f7adf30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f5c6ea-17e0-4369-ada8-29ca6bd31df8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae43675-9b21-4a8c-8e66-9c12d2f10f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6e3f8a-5ce6-4422-9fa7-dacee3caccec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14afcafe-fa4a-4dce-9975-f07690da7934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8e13cd-d97a-47c7-ad44-c8403cba1fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b9d608-0efc-46ca-87d1-0822a65e8309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706405de-1943-4185-80cf-0d6112660510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423774a6-5827-4db0-94bd-3933d13f7174",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sleap-3712)",
   "language": "python",
   "name": "sleap-3712"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
